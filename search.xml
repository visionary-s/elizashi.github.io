<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[WebUploader]]></title>
    <url>%2F2020%2F05%2F26%2FwebUploader%2F</url>
    <content type="text"><![CDATA[Using WebUploader as 3pp to upload files to system. 1. 初始化123456789101112131415161718192021222324// 仅包含了常用参数var uploader = new WebUploader.Uploader(&#123; duplicate: true, // 是否允许重复文件 default undefined auto: false, // 选完文件后，是否自动上传 swf: 'path_of_swf/Uploader.swf', // swf文件路径 server: "/upload.html", // 文件接收服务端 pick: &#123; id: "#uploadFile", innerHTML: "localImg" &#125;, // 选择文件的按钮。可选 accept: &#123; // sample, 只允许选择图片文件 title: 'Images', extensions: 'gif,jpg,jpeg,bmp,png', mimeTypes: 'image/*' &#125;, threads: 1, // 线程数 fileSingleSizeLimit: 2000, // 单文件大小限制 fileNumLimit: 10, // 单次上传文件数量限制 fileSingleSizeLimit: // 验证单个文件大小是否超出限制, 超出则不允许加入队列 compress:false, // 是否压缩上传 chunked: true, // 是否要分片处理大文件上传, default false chunkSize: 5242880, // 如果要分片，分多大一片？ default 5242880 (5M) chunkRetry: 1, // 如果某个分片由于网络问题出错，允许自动重传多少次？ default 2 threads: 1, // 上传并发数。允许同时最大上传进程数 default 3 formData:&#123;&#125;, // 文件上传请求的参数表，每次发送都会发送此对象中的参数 method: 'GET', // POST or GET, default POST &#125;); 2. 监听event仅列举常用event uploadAccept当某个文件上传到服务端响应后，会派送此事件来询问服务端响应是否有效。如果此事件handler返回值为false, 则此文件将派送server类型的uploadError事件 12345uploader.on('uploadAccept', function (file, response) &#123; if (response.error) &#123; this.uploader.trigger('uploadError', file, response.UserMessage); &#125;&#125;); uploadSuccess当文件上传成功时触发（单文件上传成功） 123uploader.on('uploadSuccess', function (file) &#123; this._saveSuccessHandler(file);&#125;); uploadError当文件上传出错时触发 1234567891011uploader.on('uploadError', function (file, reason) &#123; var xhr = &#123;&#125;, responseJSON = &#123;&#125;; responseJSON.UserMessage = reason; xhr.status = 500; xhr.responseJSON = responseJSON; if (reason) &#123; createErrorDialog(xhr, 500, "upload failed"); &#125; this.uploader.reset(); // uploader重置 this.submitBtn.removeAttribute('disabled'); &#125;); For more details: https://www.jianshu.com/p/9f669deebf82]]></content>
      <categories>
        <category>work</category>
      </categories>
      <tags>
        <tag>js</tag>
        <tag>jquery</tag>
        <tag>WebUploader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell grammar]]></title>
    <url>%2F2020%2F05%2F26%2Fshell%2F</url>
    <content type="text"><![CDATA[&gt; &amp; &gt;&gt; &gt; 创建 1$ echo "hello shell" &gt; output.txt &gt;&gt; 追加 1$ echo "hello shell" &gt;&gt; output.txt 当output.txt不存在时，两者都会创建一个新的output.txt；当output.txt存在时，前者会清空并重新写入，后者怎会在末尾追加 ref: https://blog.csdn.net/nahanai/article/details/83861449 --- ###]]></content>
      <categories>
        <category>work</category>
      </categories>
      <tags>
        <tag>cmd</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sequelize]]></title>
    <url>%2F2020%2F05%2F26%2Fsequelize%2F</url>
    <content type="text"><![CDATA[Sequelize 是一个基于 promise 的 Node.js ORM, 目前支持 Postgres, MySQL, SQLite 和 Microsoft SQL Server, 主要用来进行数据库和nodejs后端数据映射。Docs: Sequelize Docs 中文版(不全) | Official api docs Here I only mark certain api I use most frequently. Modeldefinitionuse define to map data model to table in db. 12345678910111213141516171819202122232425262728293031'use strict';module.exports = (sequelize, DataTypes) =&gt; &#123; var Cell = sequelize.define("Cell", &#123; id: &#123; type: DataTypes.INTEGER, primaryKey: true, autoIncrement: true &#125;, type: &#123; type: DataTypes.INTEGER, defaultValue:1 &#125;, name: &#123; type: DataTypes.STRING(255), unique: 'compositeIndex' &#125;, ... &#125;, &#123; timestamps: false &#125;); Cell.getCells = function () &#123; ... &#125; ...function... ...function...&#125; usage find findByPk, search element in db by primaryKey (usually id). 12345678Cell.findCell = async function (id) &#123; let cell = await Cell.findByPk(id);&#125;// or likeProject.findByPk(123).then(project =&gt; &#123;// project 将是 Project的一个实例,并具有在表中存为 id 123 条目的内容.// 如果没有定义这样的条目,你将获得null&#125;) findOne, search element in db by property. 1234567891011Cell.findCellByName = async function (name) &#123; return await Cell.findOne(&#123;where: &#123;name: name&#125;&#125;);&#125;;// if multiple propertiesProject.findOne(&#123; where: &#123;title: 'aProject'&#125;, attributes: ['id', ['name', 'title']]&#125;).then(project =&gt; &#123; // project 将是 Projects 表中 title 为 'aProject' 的第一个条目 || null // project.get('title') 将包含 project 的 name&#125;) findAndCountAll is a combination of findAll and count.It search db with conditions, return records with a data set (rows) and total count (count). Useful when you want to list data as a table, it provides with limit and offset in pagination. 1234567891011121314Project .findAndCountAll(&#123; where: &#123; title: &#123; [Op.like]: 'foo%' &#125; &#125;, offset: 10, limit: 2 &#125;) .then(result =&gt; &#123; console.log(result.count); console.log(result.rows); &#125;); Op = Operators. for more available Ops, see https://sequelize.org/master/manual/model-querying-basics.html#operators it also support include to set limits of count, or construct left join: 12345678910111213141516171819202122232425262728// only data with required attribute value equals to true will be countedUser.findAndCountAll(&#123; include: [ &#123; model: Profile, required: true &#125; ], limit: 3&#125;);// e.g. model Cells left join with model XXX.Cell.searchByNameAndPagination = async function (offs, limits, attribute, order, name) &#123; ... let cells = await Cell.findAndCountAll(&#123; include: [&#123; model: XXX // right: true // will turn to right join, only when required is false &#125;], where: where, offset: offs, limit: limits, order: orderTmp &#125;); cells.rows = cells.rows.map(function (cell) &#123; cell.dataValues.xxxname = cell.XXX ? cell.XXX.name : null; delete cell.dataValues.XXX; delete cell.dataValues.xxxId; return cell.dataValues; &#125;); return cells;&#125; findAll, similar to above, without counting. create create a new obj in current model count normally use with findAndCountAll min / max / sum return min/max/sum value with given attribute. upsert ref, Insert or update a single row. An update will be executed if a row which matches the supplied values on either the primary key or a unique key is found. 1234567891011121314return Cell.upsert(&#123; type: value.type, name: value.name, ... &#125;).then(function () &#123; successRecords.push(&#123; value &#125;); &#125;).catch(function (exc) &#123; failedRecords.push(&#123; gis: value, reason: exc.original &#125;); &#125;); According to the data model as above, this means the upsert will use id as the key to match, cuz id is the only attribute not changed in upsert.]]></content>
      <categories>
        <category>basic</category>
      </categories>
      <tags>
        <tag>node.js</tag>
        <tag>database</tag>
        <tag>backend</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Send batches of data creation requests to http server via Shell]]></title>
    <url>%2F2020%2F05%2F26%2Fsend%20quantity%20of%20http%20requests%20via%20shell%2F</url>
    <content type="text"><![CDATA[In order to test the data pool volume, send over 60000 creation data to server.Shell Script: 1234567891011#!/bin/basha=1while [ $a -le 60000 ]; do # start from 1, end by 60000 json="&#123;\"areas\":[&#123;\"new\":[58,60,57],\"id\":\"$a\", \"center\":[-39,49],\"name\":\"$1$a\",\"Version\":\"1.0\"&#125;"; a=$((a+1)) curl -v -X POST -H "Content-Type: application/json; charset=UTF-8" -H "Cookie: sessionId=_____" http://url -d "$json";done Mind the syntax especially the space, &quot;&quot; and &#39;&#39;, using \ for escaping “” inside json to avoid syntax error. other materials: curl 的用法指南]]></content>
      <categories>
        <category>work</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Require JS - define模块定义]]></title>
    <url>%2F2020%2F05%2F26%2Frequire%20js%20-%20define%E6%A8%A1%E5%9D%97%E5%AE%9A%E4%B9%89%2F</url>
    <content type="text"><![CDATA[CMD (Common Module Definition)在 CMD 规范中，一个模块就是一个文件。代码的书写格式如下： define(factory);define 是一个全局函数，用来定义模块。 1. factory为函数时，表示模块的构造方法：123define(function(require, exports, module) &#123; // 模块代码&#125;); 执行该构造方法，可以得到模块向外提供的接口。factory 为对象、字符串时，表示模块的接口就是该对象、字符串 1define(&#123; "foo": "bar" &#125;); 也可以通过字符串定义模板模块: 1define('I am a template. My name is &#123;&#123;name&#125;&#125;.'); 2. define(id, deps, factory?)字符串 id 表示模块标识，数组 deps 是模块依赖 123define('hello', ['jquery'], function(require, exports, module) &#123; // 模块代码&#125;); factory参数可以省略。省略时，表示声明依赖关系。在开发阶段，推荐不要手写 id 和 deps 参数，因为这两个参数可以在构建阶段通过工具自动生成。 注意：带 id 和 deps 参数的 define 用法不属于 CMD 规范，而属于 Modules/Transport 规范。 3. require Functionrequire接受module-name(id)作为唯一参数，用来获取其他模块提供的接口 123456define(function(require, exports) &#123; // 获取模块 a 的接口 var a = require('./a'); // 调用模块 a 的方法 a.doSomething();&#125;); 4. exports Objectexports 是一个对象，用来向外提供模块接口。 1234567define(function(require, exports) &#123; // 对外提供 foo 属性 exports.foo = 'bar'; // 对外提供 doSomething 方法 exports.doSomething = function() &#123;&#125;;&#125;); 除了给exports对象增加成员，还可以使用return直接向外提供接口。 1234567define(function(require) &#123; // 通过 return 直接提供接口 return &#123; foo: 'bar', doSomething: function() &#123;&#125;; &#125;;&#125;); TBC ref: https://blog.csdn.net/cpf506497746/article/details/8832317]]></content>
      <categories>
        <category>basic</category>
      </categories>
      <tags>
        <tag>js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Promise]]></title>
    <url>%2F2020%2F05%2F26%2Fpromise%2F</url>
    <content type="text"><![CDATA[js async - PromiseHow Promise works is that, each async task will return result and construct a Promise instance, and each instance has a then, which is used for directing to next callback func.Here is a simple promise example: 123456789function f1(resolve, reject) &#123; // async codes here..&#125;var p1 = new Promise(f1); // f1 is an async callback function/task, // promise instance p1 receives f1's result// when f1 is done, do f2p1.then(f2); // f2 is the next async func to be executed Promise changed the style of multiple nesting levels. In olde way, these steps will be written as: 123456789step1(function (value1) &#123; step2(value1, function(value2) &#123; step3(value2, function(value3) &#123; step4(value3, function(value4) &#123; // ... &#125;); &#125;); &#125;);&#125;); using Promise, it will be like: 1234(new Promise(step1)) .then(step2) .then(step3) .then(step4); Promise state123456789const promise = new Promise(function(resolve, reject) &#123; // ... some code if (/* 异步操作成功 */)&#123; resolve(value); &#125; else &#123; reject(error); &#125;&#125;); resolve and reject is two functions provided by JS engine. (no need to declare) resolve : change the state of promise obj from pending to resolved reject : change the state of promise obj from pending to rejected note: when the state is changed, nothing can be done to roll back the transaction. 我的理解是，resolve(), reject()像两个一次性boolean函数，一旦被call就会从false变为true并直接将promise实例做上resolved/rejected的状态标记。 If the Promise instance has already been generated, can use then declare the callback functions for these two state: 1234567promise.then(function(value) &#123; // success // call when state changed to resolved&#125;, function(error) &#123; // failure // call when state changed to rejected&#125;); Both functions receive result returned by Promise obj as paremeter value/error. Promise 新建后会立即执行 123456789101112131415let promise = new Promise(function(resolve, reject) &#123; console.log('Promise'); //立即执行 resolve(); // state changed, call then&#125;);// `then` 要在当前脚本的所有同步任务（同级的）都执行完才会执行promise.then(function() &#123; // only resolve func console.log('resolved.');&#125;);console.log('Hi!');// Promise// Hi!// resolved For more info : ES6入门（阮一峰） | MDN - Promise]]></content>
      <categories>
        <category>basic</category>
      </categories>
      <tags>
        <tag>js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Post photos to Gallery]]></title>
    <url>%2F2020%2F05%2F26%2FPost%20photos%20to%20Gallery%2F</url>
    <content type="text"><![CDATA[How to post a photo to blog gallery1. Setup the gallery page:12345$ hexo new page gallery // create 'gallery' page$ hexo new page about // create 'about' page$ hexo new page tags // 'tags' page$ hexo new page categories // 'categories' page 2. Find the index.md and modify it.After step 1, there will be folders named “gallery”, “about”… under /source/. And you can find a file named “index.md” generated automatically under these folders.Open and modify the front-matter part as : 1234567---title: Galleryalbums: [ ["img_url","img_caption"], ["img_url","img_caption"] ]--- use outer links can be a better way as internal insert of images will decrease loading speed.(I haven’t find a good-way to insert as internal files, so I turned to use weibo-albums-link as alt… ). There was something wrong that photos didn’t display successfully in mobile mode. 190725 Update: Problem fixed with changing photo cloud storage from weibo to cloudinary. (weibo albums no longer support free external ref links) same way to edit the “about” page]]></content>
      <categories>
        <category>interest</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Some tips about OpenLayer]]></title>
    <url>%2F2020%2F05%2F26%2Fopenlayer-knowledge%2F</url>
    <content type="text"><![CDATA[Using openlayer in work currently and need to write down some notes about it. EPSG 4326 VS EPSG 3857地理Coordiante系统由EPSG编号标识。最常用于网络地图应用的两个坐标系统是EPSG：4326和EPSG：3857。 EPSG：4326（又名WGS84，未投影）是一个地理的非项目坐标系。它是lat，longs GPS显示器，单位是十进制度。EPSG：4326无法在平面地图上以有意义的方式显示。 EPSG：3857（又名Pseudo-Mercator，球形墨卡托或Web墨卡托）是投影坐标系。这是Google Maps和几乎所有其他Web制图应用程序使用的坐标系。 通常，数据存储在EPSG：4326中并显示在EPSG：3857中，自行转换。 ref link Function to draw a sector accuratelyCuz the untransformed sector displayed with great error in angle = 45° (start angle) so I have to turn to this Function as following, which convert longitude and latitude into Mercator projection first before the calculation. 12345678910111213function GetMarcoXyArcArray(origin,radius,sides,r,angel) &#123; var x = []; x[0] = [origin[0],origin[1]]; for (var j = 1; j &lt; sides; j++) &#123; var tx = origin[0] + radius * Math.cos(Math.PI / 180 * (90 - angel + (sides/2 - j) * r / (sides-2))); var ty = origin[1] + radius * Math.sin(Math.PI / 180 * (90 - angel + (sides/2 - j) * r / (sides-2))); x[j]=[tx,ty]; &#125; //alert(x); return new ol.geom.Polygon([x]); &#125; Thanks to tianshibufan521’s post After modification: 190813 updatethis method will lead to wrong presentation size at about 4/5 of expected radius due to the Mercator projection. I couldn’t figure out why for the second time I tried the origin calculation method as following, it turned out to appear normally with start angle of 45°. 123456789101112131415for (var i = 0; i &lt; sides; ++i) &#123; rotatedAngle = (i * radian / 360 * 2 * Math.PI / sides) + (90 - angle - radian / 2 )* Math.PI / 180 ; // start from y = 0 (sector1 based on symmetry y axis, clockwise rotation) coordinate = this.getJWD(origin.Longitude, origin.Latitude, radius, rotatedAngle); // method getJWD() can be found ↓ link points.push(coordinate);&#125;// if not circle, add center point.// this allows drawing circle via polygon apiif (radian !== "360") &#123; points.push([origin.Longitude, origin.Latitude]);&#125;var ring = new ol.geom.LinearRing(points);var pointsCoords = ring.getCoordinates();feature = new ol.Feature(new ol.geom.Polygon([pointsCoords])); calculate longitude &amp; latitude via coordinateformer dev using func getJWD to calculate the coordinates, but this func cause the display error with start degree of 45°, so I discarded it.For more info about this func : link Draw a circleSimply used ol.geom.Circle instead of ol..geom.Polygon, which will cause a start/end radius as follows: Before After 12345var circle = new ol.geom.Circle( ol.proj.transform([longitude, latitude], 'EPSG:4326', 'EPSG:3857'), radius);var circleFeature = new ol.Feature(circle); OpenLayer Samples link || Circle update:The pattern turned out to be simple circle pattern，which does not include geometry params，but our project need geometry params in GeoJSON format to decide which area is covered.So I finally turn to ol/geom/Polygon.fromCircle which transform plain circle into Polygon format. It returns Polygon geometry so that can be used in further calculation of coverage. 12var circle = new OpenLayers.geom.Circle(circleParams.center, circleParams.radius);feature = new OpenLayers.Feature(new OpenLayers.geom.Polygon.fromCircle(circle, 500));]]></content>
      <categories>
        <category>work</category>
      </categories>
      <tags>
        <tag>js</tag>
        <tag>openlayer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NBI & SBI]]></title>
    <url>%2F2020%2F05%2F26%2FNBIandSBI%2F</url>
    <content type="text"><![CDATA[Northbound InterfaceNBI conceptualizes lower level details (e.g. data or functions) used by, or in the component. It interfaces to higher level layers and is normally drawn at the top of an architectural overview.e.g. REST API, SMMP, CORBA, SNMP北向接口，用于接口编程开发各app，采集、分析app在运行中产生的各种数据，因网络管理中从上而下分应用层、数据处理层、数据管理层，北向接口即应用层和数据处理层之间的数据交互定义接口（见下图），因为朝上（上北下南）称北向接口。 Southbound InterfaceA southbound interface decomposes concepts in the technical details, mostly specific to a single component of the architecture. Southbound interfaces are drawn at the bottom of an architectural overview.e.g. OpenFlow, NETCONF, XMPP A Northbound interface goes “up” and a Southbound interface goes “down”.northbound interfaces go towards the core of the data center or towards the Internet-facing egress of the network. Southbound goes towards the end-users/servers/VMs.Northbound interfaces normally talk to southbound interfaces of higher level components and vice versa.]]></content>
      <categories>
        <category>work</category>
      </categories>
      <tags>
        <tag>network</tag>
        <tag>interface</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mini-program project demo for starter]]></title>
    <url>%2F2020%2F05%2F26%2Fmini-program%2F</url>
    <content type="text"><![CDATA[demo program 我要圣诞帽https://github.com/jasscia/ChristmasHat 图片编辑，存图 掌故https://github.com/Gesangs/PhoneStory 新闻推送 简约睡眠Musichttps://github.com/shajinyang/BeautyAudio 音乐播放器 运势小程序https://github.com/panyefan/wxfortune 测运势，存图 跑马灯，左侧菜单，抽屉层，加载动画https://github.com/youzouzou/wxapp 小程序组件合集 订单管理，浮层菜单，页面设计https://github.com/GavinCarter1991/wx-onePro 内部平台，商户端界面 电商模板，购物车模板https://github.com/fangliu520/wxbestcake 摇一摇，二维码《微信小程序入门与实践》一书的小程序源代码前端： https://github.com/7insummer/orange-can 后端： https://github.com/7insummer/orange-can-server 仿微信运动步数排行https://www.jianshu.com/p/bb7131114993 Note. 以上代码都有两年左右年份，仅供入门学习参考ref: https://www.jianshu.com/p/0e471853a548 UI Lab iViewhttps://github.com/TalkingData/iview-weapp 教程：https://www.jianshu.com/p/09b4515152ff]]></content>
      <categories>
        <category>interest</category>
      </categories>
      <tags>
        <tag>mini-program</tag>
        <tag>resource</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Migrate local video header to cloud storage]]></title>
    <url>%2F2020%2F05%2F26%2FMigrate%20local%20video%20header%20to%20cloud%20storage%2F</url>
    <content type="text"><![CDATA[Since the Ocean theme includes and initiates the videos and images about header via local folder themes/ocean/source/images/ocean/, the page loads slowly at mobile device. So I decided to transfer these large files to cloud side to promote loading speed. Find the local image folder as referred above. upload these files to cloudinary, it provides plugin as a module to js file: 1cloudinary.videoTag('gitblog/ocean/ocean_j5rpnt').toHtml(); the src ref-way can be find at “edit” page by right clicking on cloudinary/file.Here I did not use this short path cuz I am not in need of a large quantity of inserted files. Modify themes/ocean/_config.yml: 1234567# Ocean Video# Because I put videos in multiple formats on the same path, I just labeled the path here.ocean: overlay: true path: https://res.cloudinary.com/elizashi/ # path: /images/ocean/ brand: /images/ming-inverted.svg Find the ocean.ejs file in themes/ocean/layout/_partial/, and modify as follows: 12345&lt;% if (theme.ocean.overlay) &#123; %&gt; &lt;div class="video-frame"&gt; &lt;img src="&lt;%- theme.ocean.path %&gt;image/upload/v1564042232/gitblog/ocean/overlay-hero_hfo1px.png" alt="Decorative image frame"&gt; &lt;/div&gt;&lt;% &#125; %&gt; 12345678910&lt;div class="video-media"&gt; &lt;video playsinline="" autoplay="" loop="" muted="" data-autoplay="" poster="&lt;%- theme.ocean.path %&gt;image/upload/v1564042234/gitblog/ocean/ocean_dvmafj.png" x5-video-player-type="h5"&gt; &lt;source src="&lt;%- theme.ocean.path %&gt;video/upload/v1564042238/gitblog/ocean/ocean_j5rpnt.mp4" type="video/mp4"&gt; &lt;source src="&lt;%- theme.ocean.path %&gt;video/upload/v1564042232/gitblog/ocean/ocean_p4kg5c.ogv" type="video/ogg"&gt; &lt;source src="&lt;%- theme.ocean.path %&gt;video/upload/v1564042238/gitblog/ocean/ocean_qgwvjh.webm" type="video/webm"&gt; &lt;p&gt;Your user agent does not support the HTML5 Video element.&lt;/p&gt; &lt;/video&gt; &lt;div class="video-overlay"&gt;&lt;/div&gt;&lt;/div&gt; As I mentioned that I am not using many external src so I modify each file address one by one.If files come to more, shall turn to use the cloudinary.videoTag func to insert files or the code will get lengthy and jumbled.]]></content>
      <categories>
        <category>interest</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux CMD for daily use]]></title>
    <url>%2F2020%2F05%2F26%2Flinux-cmd%2F</url>
    <content type="text"><![CDATA[check log Display whole log file content: 1$ cat target.log Search key word in log file, and return lines containing keyword: 123$ cat target.log |grep "keyword"or$ grep -i "keyword" target.log these two method return same result Check the most recent log (the tail lines of log file): 123$ cat target.log |tail -n 200 # check the last 200 lines of log fileor$ tail -200f target.log # show last 200 lines and continue printing new logs ping To test whether the target host is accessible, mainly has two ways: 12$ ping &lt;host addr&gt; # sample address: 192.168.1.21$ ping6 &lt;host addr&gt; # ipv6 address ping + paras: 1234567$ ping -a &lt;addr&gt; # 把地址解析成主机名 (NetBios名) # e.g. ping -a 192.168.1.21 returns # Pinging iceblood.yofor.com [192.168.1.21] with 32 bytes of data # so the NetBios name is iceblood.yofor.com with ip=192.168.1.21$ ping -t &lt;addr&gt; # continue pinging the addr # press Ctl+Break to show statistic info and continue pinging # Ctl+C to stop For more: 从ping和ping6说起 file transport (scp) copy file from path1 to path2 12345$ scp path1 username@targetAddr:path2# sample:$ scp /home/usrsby/xxx.jar root@10.136.40.75:/home/usrsby# while using jumper as proxy, file has to be transported twice$ scp /home/usrsby/xxx.jar node-image-name:/opt/xxx/xx-xx/xxx-server/repository/com/xxx/x/xx-service-configuration/1.0-SNAPSHOT/ download file from remote vm: 12345# Step1: copy target file from vm to jumper in same way as above# Step2: download file to jumper, execute in jumper$ scp username@remoteAddr:/remotePath/file folder_in_jumper# Sample:$ scp root@10.136.40.75:/home/usrsby/xx.log /home/usrsby when copy a folder:Append -r after scp like: 12$ scp -r /tmp/tempA/ root@10.127.40.25:/tmp/usrsby/ # copy tempA folder to usrsby# !notice: do not dismiss "/" at the end of target path, not same as copying single file For more: linux利用scp远程上传下载文件/文件夹 timeto show current local time: 1$ date grep, awk &amp; sedAWSOME specific summary! –&gt; A brief introduction to grep, awk &amp; sed grep (Global Regular Expression Print) is used to search for specific terms in a file. 1$ grep 'test' file.txt awk is a text pattern scanning and processing language, which is created by Aho, Weinberger &amp; Kernighan. awk is mostly used for data extraction and reporting (dealing with .csv files). 123456# print 1st and 4th column$ awk '&#123;print $1, $4&#125;' file.txt## same with 'cat file.txt'$ awk '&#123;print $0&#125;' file.txt# for more see the reference sed refers to Stream Editor. It can perform text transformations on a given file or an input stream. 1234567891011121314# replace the 1st 'test' with 'text' in each linesed 's/test/text/' file.txt## replace all 'test' with 'text' in each linesed 's/test/text/g' file.txt## replace the 2nd 'test' with 'text' in each linesed 's/test/text/2' file.txt## replace all 'test' from the 2nd to the end of each line with 'text'sed 's/test/text/2g' file.txt## replace the 'test' in the 2nd line with 'text'sed '2s/test/text/g' file.txt 2&gt;/dev/null 1&gt;&amp;2https://unix.stackexchange.com/questions/163352/what-does-dev-null-21-mean-in-this-article-of-crontab-basicshttps://stackoverflow.com/questions/818255/in-the-shell-what-does-21-mean –https://unix.stackexchange.com/questions/11376/what-does-double-dash-mean switch to root usersu –&gt; enter password of root user packaging and unzip (extraction) unzip ：$ tar zxvf fileName.tar.gz packaging: tar zcvf fileName.tar.gz dirPath file typefor details, see https://blog.csdn.net/rong09_13/article/details/79233956 1$ file &lt;fileName&gt; search history cmduse ctrl + r to search history input, continue input until find the target cmd, then press Enter to execute. Port check port status1lsof -i:&lt;port-id&gt; e.g. 123[root@host63 ~]# lsof -i:32228COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEkube-prox 21592 root 16u IPv6 171971606 0t0 TCP *:32228 (LISTEN) check the process running on certain port1netstat -tunlp | grep &lt;port-id&gt; e.g. 12[root@host63 ~]# netstat -tunlp | grep 32228tcp6 0 0 :::32228 :::* LISTEN 21592/kube-proxy]]></content>
      <categories>
        <category>work</category>
      </categories>
      <tags>
        <tag>cmd</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[K8s - kubectl]]></title>
    <url>%2F2020%2F05%2F26%2FKubernetes%2F</url>
    <content type="text"><![CDATA[Every time before start kubectl, remember export admin.config file first which contains server info for connection. The pwd should under path where the config file lies. 1$ export KUBECONFIG=./admin.conf then start nodes 1$ kubectl get node or 1$ kubectl get node -n testing useful cmd 通过bash获得pod中某个容器的TTY，相当于登录容器1$ kubectl exec -it &lt;pod-name&gt; -c &lt;container-name&gt; -- bash ref: kubectl 常用命令总结 --shell命令前，要加– 号，不然shell命令中的参数，不能识别 https://www.wandouip.com/t5i281271/ 获取异常容器 (for debug) 1$ kubectl get pods -n kube-system | grep -v Running get pod description (for debug) 1$ kubectl describe pod &lt;pod-name&gt; -n &lt;namespaces-name&gt; 查看异常pod的日志 (for debug) 1$ kubectl logs &lt;pod-name&gt; -n &lt;namespaces-name&gt; 查看相关的config map存不存在 (for debug) find the path to configmap file first 1$ ls -l # if the result is "total 0", means the configmap is not exist delete pod 1$ kubectl delete pod &lt;pod-name&gt; -n &lt;namespaces-name&gt; -n &lt;namespaces-name&gt; can be omitted. delete pods in batches (e.g. delete all evicted pods) 1$ kubectl get pods -A| grep Evicted | awk '&#123;print $2&#125;' | xargs kubectl delete pod -n cec create namespace1$ kubectl create namespace &lt;name&gt;]]></content>
      <categories>
        <category>work</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
        <tag>K8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JS对象引用]]></title>
    <url>%2F2020%2F05%2F26%2FJS%E5%AF%B9%E8%B1%A1%E5%BC%95%E7%94%A8%2F</url>
    <content type="text"><![CDATA[如果不同的变量名指向同一个对象，那么它们都是这个对象的引用，也就是说指向同一个内存地址。修改其中一个变量，会影响到其他所有变量。 12345678var o1 = &#123;&#125;;var o2 = o1;o1.a = 1;o2.a // 1o2.b = 2;o1.b // 2 上面代码中，o1和o2指向同一个对象，因此为其中任何一个变量添加属性，另一个变量都可以读写该属性。 如果取消某一个变量对于原对象的引用，不会改变已经引用过的另一个变量。 1234567var o1 = &#123;&#125;;var o2 = o1;o1 = 1;console.log(o2); // &#123;&#125;console.log(o1); // 1console.log(typeof o1); // number 上面代码中，o1和o2指向同一个对象，然后o1的值变为1，这时不会对o2产生影响，o2还是指向原来的那个对象。 注意：这种引用只局限于object,如果两个变量指向同一个原始类型的值，则变量这时都是值的拷贝。 12345var x = 1;var y = x;x = 2;y // 1 上面代码中，当x的值变化后，y值不变，这就表示y和x并不是指向同一个内存地址。 ref: 阮一峰]]></content>
      <categories>
        <category>basic</category>
      </categories>
      <tags>
        <tag>js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JS-Label]]></title>
    <url>%2F2020%2F05%2F26%2FJS-Label%2F</url>
    <content type="text"><![CDATA[标签（label），相当于定位符，用于跳转到程序的任意位置。 配合break 1234567891011top: // Label for (var i = 0; i &lt; 3; i++)&#123; for (var j = 0; j &lt; 3; j++)&#123; if (i === 1 &amp;&amp; j === 1) break top; // 注意，不加引号 console.log('i=' + i + ', j=' + j); &#125; &#125;// i=0, j=0// i=0, j=1// i=0, j=2// i=1, j=0 如果满足if，直接跳出双重循环。 配合continue 1234567891011121314top: for (var i = 0; i &lt; 3; i++)&#123; for (var j = 0; j &lt; 3; j++)&#123; if (i === 1 &amp;&amp; j === 1) continue top; console.log('i=' + i + ', j=' + j); &#125; &#125;// i=0, j=0// i=0, j=1// i=0, j=2// i=1, j=0// i=2, j=0// i=2, j=1// i=2, j=2 当i=1，j=1时，跳过打印（当前内层循环）直接进行下一个外层循环（不会跳出top） label用于跳出代码块12345678foo: &#123; console.log(1); break foo; console.log('本行不会输出');&#125;console.log(2);// 1// 2 ref: 阮一峰]]></content>
      <categories>
        <category>basic</category>
      </categories>
      <tags>
        <tag>js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JS getter]]></title>
    <url>%2F2020%2F05%2F26%2Fjs-getter%2F</url>
    <content type="text"><![CDATA[Encountered with the following function as below: 12345678910static get userFilter() &#123; return &#123; dataset1: &#123; value: '...' &#125;, dataset2: &#123; value: '...' &#125; &#125;;&#125; so question comes up: Whats the meaning of ‘static get’ in Javascript (ES6)? According to the above answer, static defines that this function inside class is static, which means you cannot call the func via the instance of the class1234567891011121314// e.g.class Agent &#123; static get CIRCLE() &#123; return 1; &#125; static get SQUARE() &#123; return 2; &#125;&#125;// you call this as a property directlyAgent.CIRCLE; // 1// but call by an instance is not allowedconst newAgent = new Agent();console.log(newAgent.CIRCLE); // undefined or TypeError: foo.classMethod is not a function Lookup: Static method | Class的基本语法 2.静态方法 get syntax binds an object property to a function that will be called when is property is looked up123456789// e.g.const obj = &#123; log: ['example','test'], get latest() &#123; if (this.log.length === 0) return undefined; return this.log[this.log.length - 1]; &#125;&#125;console.log(obj.latest); // "test". Note: the above code will create a pseudo-property latest for object obj, which will return the last array item in log, but the attempt to assign a value to latest will not change it. For more details, see MDN&gt;JavaScript reference&gt;Functions&gt;getter]]></content>
      <categories>
        <category>basic</category>
      </categories>
      <tags>
        <tag>js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo Theme Modification]]></title>
    <url>%2F2020%2F05%2F26%2FHexo%20Theme%20Modification%2F</url>
    <content type="text"><![CDATA[Modify the Theme in the following branch: 1Source/themes/&lt;Theme folder name&gt;/layout/_partial/*.ejs]]></content>
      <categories>
        <category>interest</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo - Tools & cmd used during deployment]]></title>
    <url>%2F2020%2F05%2F26%2FHexo%20cmd%2F</url>
    <content type="text"><![CDATA[Ref: https://caiyantao.gitee.io/2019/04/13/Hexo-%E4%B8%80/ npm CN image（taobao）1$ npm install -g cnpm --registry=https://registry.npm.taobao.org Hexo installation1$ cnpm install -g hexo-cli check if successfully installed 1$ hexo -v 123456789101112131415161718hexo: 3.9.0hexo-cli: 2.0.0os: Windows_NT 10.0.16299 win32 x64http_parser: 2.8.0node: 10.16.0v8: 6.8.275.32-node.52uv: 1.28.0zlib: 1.2.11brotli: 1.0.7ares: 1.15.0modules: 64nghttp2: 1.34.0napi: 4openssl: 1.1.1bicu: 64.2unicode: 12.1cldr: 35.1tz: 2019a Local init for first time setup1$ hexo init Start server and Run in browser1$ hexo s Visit http://localhost:4000/ Add ssh-keyPass When error generated (local compile)123$ hexo clean$ hexo g # gengerate post to public folder$ hexo s Deploy to github1$ hexo d]]></content>
      <categories>
        <category>interest</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hard & Soft Dependencies]]></title>
    <url>%2F2020%2F05%2F26%2FHard%20or%20Soft%20Dependencies%2F</url>
    <content type="text"><![CDATA[ref: https://magento.stackexchange.com/questions/151250/whats-a-hard-dependency-and-whats-a-soft-dependency Hard Dependencya module cannot function without the other modules on which it depends The module contains code that directly uses logic from another module (instances, class constants, static methods, public class properties, interfaces and traits). The module contains strings that include class names, methods names, class constants, class properties, interfaces, and traits from another module. The module de-serializes an object declared in another module. The module uses or modifies the database tables used by another module. Soft Dependencya module can function without the other modules on which it depends The module directly checks another module’s availability. The module extends another module’s configuration. The module extends another module’s layout.]]></content>
      <categories>
        <category>basic</category>
      </categories>
      <tags>
        <tag>js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git cmd for daily use]]></title>
    <url>%2F2020%2F05%2F26%2Fgit-for-daily-use%2F</url>
    <content type="text"><![CDATA[Codes commit procedure for daily work:1$ git status # check current modifications can skip these steps: 123$ git stash # save work (current modifications)$ git stash list # check to see saved work$ git stash apply 0 # apply work-id to restore the work to tmp branch git stash 用法总结和注意点 1$ git add . # do not miss "." or 1$ git add -u add -u 和 add . 的区别 Check status and see that modifications displayed in green. 1$ git commit -m "[Task/Bug] Jira-id : Jira Task content." Notice: better to build locally first and see if it will get failed. (Close local server before building, no need to close db server on docker) how to build:1$ ./startindesignenv.sh -c sometimes it failed due to late version of project, checkout and pull the latest version. 1$ git pull # pull the update to local branch 12$ git rebase -i master # rebase multi local submits and get sync with new branch on master and local, conflicts may occur if late-version conflicts occur, reset to last commit version, use git rebase to modify commit which is not pushed: link 12$ git log # check commit history$ git reset &lt;commit id&gt; # reset to certain commit version If build failed, you should redo “add” and “commit” step after resetting. Tip: git log only show commit history of default remote branch (usually master). If remote has multiple branches in work, use git log --all to check full historical submits. Final Step： 1$ git push origin HEAD:refs/for/master Remember check Gerrit and add reviewers when work pushed. After the work is successfully built on cloud and get merged, add resolved mark and commit on JIRA task system. .amend &amp; reset:if something wrong with codes was found in code review and have to add modifications, you should try to use amend to change the Last Commit to modify commit message: 1$ git commit --amend to modify changed (already pushed) submit without abandon:add modified local files, then do 1$ git commit --amend --no-edit For more info about using amend :Rewriting historygit commit –amend用法(摘抄) If unfortunately failed to amend the commit, go back to last commited submit: 1$ git reset --hard &lt;commit-id&gt; remember to pull down the latest version in this step, then resubmit the new changes. .branch &amp; merge:Create a personal branch (excluded from master) locally: 123$ git branch &lt;declare a new branch name here&gt; # create# e.g. git branch test-branch$ git branch # view all existing branches Switch to certain branch: 1$ git checkout &lt;branch name&gt; push local commit to remote repository: 1234# when push current branch to remote$ git push origin test-branch# when push another branch to remote repository$ git push origin &lt;local_branch_name&gt;:&lt;remote_branch_name&gt; pull master branch to current branch: 1$ git merge master .git add not workToday I encountered with a problem that git add . did not work. The reason might be that someone else is pushing his work to main repository throght branch master while I was also trying to add my work on same branch then.The solution is simple, use: 1$ git add -A # equal to --all Cuz the work I was working on is changed to untracked status for forking reason. .git crashed起因：deploy自己的react练手项目到Heroku上时，因为react-script 3.3.0在webpack上不靠谱的脚本遇到websocket错误，在本地更改node_module里的脚本完，手贱把gitignore里的/node_module去掉后git add -A试图上传github, 放弃并cancel以后再打开git bash，把react-script downgrade到3.2.0再次提交时发现: 12345678$ git add .fatal: Unable to create '.../.git/index.lock': File exists.Another git process seems to be running in this repository, e.g.an editor opened by 'git commit'. Please make sure all processesare terminated then try again. If it still fails, a git processmay have crashed in this repository earlier:remove the file manually to continue. Solution: Find the .../.git/index.lock file and delete it. Then reopen git bash. .re-login after changing password1$ git config --global credential.helper wincred # for Windows, different from mac OS Then just use git cmd like git pull, credential confirm dialog will popup, enter the updated password. .check remote branches: 1$ git branch -r Push to remote branch which is not master 1$ git push origin HEAD:refs/for/&lt;branch-name&gt;]]></content>
      <categories>
        <category>work</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>cmd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[File Upload and Display]]></title>
    <url>%2F2020%2F05%2F26%2FFileUploadAndDisplay%2F</url>
    <content type="text"><![CDATA[input [type=file] 获取上传文件的内容 Modify: 1234567891011121314151617181920212223242526_addFileContent: function (fileTag) &#123; fileTag.addEventHandler("click", function () &#123; $("#fileUpload").change(function () &#123; var file = document.getElementById("fileUpload"); if (file.files.length &gt; 0) &#123; var trueFile = file.files[0]; console.log(document.getElementById("fileContent").value); var reader = new FileReader(); reader.readAsText(trueFile, 'UTF-8'); reader.onload = function () &#123; if (reader.error) &#123; console.log(reader.error); &#125; else &#123; var urlData = this.result; document.getElementById("fileContent").value = urlData; &#125; &#125;; &#125; else &#123; console.log("Failed to upload file!"); &#125; &#125;); &#125;); &#125; Other ref:Change event | MDN]]></content>
      <categories>
        <category>work</category>
      </categories>
      <tags>
        <tag>js</tag>
        <tag>jquery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ES6 - Template strings]]></title>
    <url>%2F2020%2F05%2F26%2FES6-Template%20String%2F</url>
    <content type="text"><![CDATA[刷题的时候遇到了这个新语法 - 模板字符串，记录一下用法。 是增强版的字符串，用反引号（`）标识。主要用法： 作为普通字符串使用 1`string text` 定义多行字符串 1234console.log(`string text line 1string text line 2`);// "string text line 1// string text line 2" 在字符串中嵌入变量 12let expression = "xxxx";`string text $&#123;expression&#125; string text` 标签模板 (tagged template)相当于一个模板函数，tag表示函数，整个表达式的返回值，就是tag函数处理模板字符串后的返回值。 123456let a = 5;let b = 10;tag`Hello $&#123; a + b &#125; world $&#123; a * b &#125;`;// 等同于tag(['Hello ', ' world ', ''], 15, 50); For more specific explanation:MDN阮一峰 (start from section 5)]]></content>
      <categories>
        <category>basic</category>
      </categories>
      <tags>
        <tag>js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tips for create-react-app]]></title>
    <url>%2F2020%2F05%2F26%2Fcreate-react-app%2F</url>
    <content type="text"><![CDATA[This is a recording work while using create-react-app. [ERROR] SKIP_PREFLIGHT_CHECK=trueerror happens when run npm start: Solution: create a new file named .env in folder. write cmd SKIP_PREFLIGHT_CHECK=true into the file, save and restart npm. change the localhost port 3000 write in .env file with: 1PORT=2200 This works on Windows, not tried on Mac OS. On windows with npm (works): in package.json: 1234"scripts": &#123; "start": "set PORT=2200&amp;&amp;react-scripts start", ...&#125; On Windows with yarn (not tried): in package.json: 123"scripts": &#123; "start": "set PORT=2200 &amp;&amp; react-scripts start", .... using npm cross-env (not tried): 1234"scripts": &#123; "start": "cross-env PORT=3006 react-scripts start", ...&#125; This method need to install cross-env to project first: 1$ npm install --save-dev cross-env [ERROR] Module not found: Can’t resolve ‘react-router-dom’ in ‘C:...\my-cv\src’It means dependency react-router-dom have not been added/installed. just run: 1$ npm install react-router-dom The dependency will be automatically added to package.json and package-lock.json with latest version. Then npm start again. Add stylesheets (Sass) install node-sass: 1$ npm install node-sass --save rename &lt;filename&gt;.css file to &lt;filename&gt;.module.scss. About .module: 个人理解是为了避免同名的class作用域互相影响，把这个stylesheet限定仅用于此module (即编译后class前加一个stylesheetname-前缀，用以区分) For more details, see CSS Modules part in this post. [Heroku ERROR] SecurityError: Failed to construct ‘WebSocket’SecurityError: Failed to construct &#39;WebSocket&#39;: An insecure WebSocket connection may not be initiated from a page loaded over HTTPS. This is due to react-scripts 3.3.0, check webpack script in node_modules/react-dev-utils/webpackHotDevClient.js: 1234// ...// line 62, the original protocol is 'ws', change it to: protocol: window.location.protocol === 'https:' ? 'wss' : 'ws', // which means using 'wss' when connection is secure But the problem is not resovled, cuz when Heroku deploy the app, it automatically downloads the node_modules, which will rewrite the script. So the only way I can fix this issue at present is downgrade react-scripts to 3.2.0 in package.json. For more discussion about this problem, see stackoverflow.]]></content>
      <categories>
        <category>interest</category>
      </categories>
      <tags>
        <tag>js</tag>
        <tag>framework</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CDT Learning]]></title>
    <url>%2F2020%2F05%2F26%2FCDT0%2F</url>
    <content type="text"><![CDATA[Skeleton123456789101112131415my-app/ .cdt # installed lib and conf，do not modify help/ # help docs locales/ # translation files resources/ # imgs &amp; other resources that are not js files src/ # src code. Contains only one folder (my-app) my-app/ # name = app name, fully lowercase test/ bit/ # FT, API concerned only unit/ # UT .editorconfig # coding styles，已删 .gitignore app.config.js # metadata for app build.json # used by the build module container.config.js # only for dev, never used in production, contains dev version of container app.config.js app configuration file, example: 123456789101112131415161718192021 define(&#123; script: 'active-alerts/ActiveAlerts', // path to app, src下的脚本执行 title: 'Active Alerts', // app title, used in breadcrumb widget // opt parent: 'alert-management', // opt, when exe parent script will start the children children: [ &#123;app: 'alerts-log'&#125;, &#123;app: 'alerts-settings'&#125; ], // opt, expose app modules that can be loaded by other apps dynamically exports: &#123; 'active-alerts/Module1': 'active-alerts/modules/Module1', 'active-alerts/Module2': 'active-alerts/modules/Module2' &#125; // i18n.locales: list of supported language "i18n": &#123; // 这里可以不加引号，也可以加，上面的参数同理 // ES6可以不加，ES5要加 "locales": ["en-us"] &#125;&#125;); detailed folder structure: internal linkother link: breadcrumb widget]]></content>
      <categories>
        <category>work</category>
      </categories>
      <tags>
        <tag>CDT</tag>
        <tag>dev-env</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CDT Learning]]></title>
    <url>%2F2020%2F05%2F26%2FCDT%2F</url>
    <content type="text"><![CDATA[Skeleton123456789101112131415my-app/ .cdt # installed lib and conf，do not modify help/ # help docs locales/ # translation files resources/ # imgs &amp; other resources that are not js files src/ # src code. Contains only one folder (my-app) my-app/ # name = app name, fully lowercase test/ bit/ # FT, API concerned only unit/ # UT .editorconfig # coding styles，已删 .gitignore app.config.js # metadata for app build.json # used by the build module container.config.js # only for dev, never used in production, contains dev version of container app.config.js app configuration file, example: 123456789101112131415161718192021 define(&#123; script: 'active-alerts/ActiveAlerts', // path to app, src下的脚本执行 title: 'Active Alerts', // app title, used in breadcrumb widget // opt parent: 'alert-management', // opt, when exe parent script will start the children children: [ &#123;app: 'alerts-log'&#125;, &#123;app: 'alerts-settings'&#125; ], // opt, expose app modules that can be loaded by other apps dynamically exports: &#123; 'active-alerts/Module1': 'active-alerts/modules/Module1', 'active-alerts/Module2': 'active-alerts/modules/Module2' &#125; // i18n.locales: list of supported language "i18n": &#123; // 这里可以不加引号，也可以加，上面的参数同理 // ES6可以不加，ES5要加 "locales": ["en-us"] &#125;&#125;); detailed folder structure: internal linkother link: breadcrumb widget]]></content>
      <categories>
        <category>work</category>
      </categories>
      <tags>
        <tag>CDT</tag>
        <tag>dev-env</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CDT App Lifecycle]]></title>
    <url>%2F2020%2F05%2F26%2Fcdt-app-lifecycle%2F</url>
    <content type="text"><![CDATA[Apps that run in the container have their lifecycle managed.The container checks for various functions implemented by the app. If those functions are implemented, the container will execute them accordingly. The following functions are supported by the container: 1. void onStart()This method is called when the app is first instantiated in the current tab for the first time. 123onStart: function() &#123; // Code here&#125; 2. void onPause()This method is called when the user has left your app to view a different app. 123onPause: function() &#123; // Code here&#125; 3. void onResume()This method is called when the user has navigated away from the app to a different app, and has navigated back. 123onResume: function() &#123; // Code here&#125;]]></content>
      <categories>
        <category>work</category>
      </categories>
      <tags>
        <tag>CDT</tag>
        <tag>dev-env</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gson LinkedTreeMap]]></title>
    <url>%2F2020%2F05%2F26%2FAbout%20Gson%20LinkedTreeMap%2F</url>
    <content type="text"><![CDATA[ProblemGiven a Gson object with format LinkedTreeMap&lt;String, String&gt;, e.g.: 123456LinkedTreeMap&lt;String, String&gt; misc = &#123; misc1: misc_site, misc2: misc_sector, misc3: null, misc4: null&#125; I got the HashMap with 12345&#123; misc: null&#125;and&#123;&#125; And pass case assertThat(misc).isNull(); is what I expected. Unfortunately both were deleted not Null.I try to transform the type into HashTable but got: 1ERROR: com.google.gson.internal.LinkedTreeMap cannot be cast to java.util.Hashtable SolutionConstruct an Iterator to get each value in map in sequence (LinkedTreeMap has already did it). 1234567Iterator it = misc.keySet().iterator();Integer cnt = 0;while (it.hasNext()) &#123; String key = (String) it.next(); if (misc.get(key) != null) cnt++;&#125;assertThat(cnt).isEqualTo(0); 不怎么好看不过能用。。 Ref: Gson解析时对于不确定泛型的处理]]></content>
      <categories>
        <category>work</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>data structure</tag>
        <tag>FT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Timeout in Node.JS]]></title>
    <url>%2F2020%2F05%2F19%2Fnodejs-req-timeout%2F</url>
    <content type="text"><![CDATA[Thanks for answers in https://stackoverflow.com/questions/6214902/how-to-set-a-timeout-on-a-http-request-in-node The problem can mainly divided into two part in my implemention: connection timeout response timeout connection timeout On request stage: 12345678910111213// set the desired timeout in optionsconst options = &#123; //... timeout: 3000,&#125;;// create a requestconst request = http.request(options, response =&gt; &#123; // your callback here&#125;);// use its "timeout" event to abort the requestrequest.on('timeout', () =&gt; &#123; request.abort();&#125;); response timeout On response stage: 123456789101112131415161718var options = &#123; ... &#125;var req = http.request(options, (res) =&gt; &#123; // Usual stuff: on(data), on(end), chunks, etc...&#125;);req.on('socket', (socket) =&gt; &#123; socket.setTimeout(myTimeout); socket.on('timeout', () =&gt; &#123; req.destroy(); &#125;);&#125;);req.on('error', (err) =&gt; &#123; if (err.code === "ECONNRESET") &#123; console.log("Timeout occurs"); //specific error treatment &#125; //other error treatment&#125;);req.end();]]></content>
      <categories>
        <category>basic</category>
      </categories>
      <tags>
        <tag>js</tag>
        <tag>nodejs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tips when using postgresql]]></title>
    <url>%2F2020%2F05%2F18%2Fpostgres-tips%2F</url>
    <content type="text"><![CDATA[[ERROR] column “xxx” does not existThis issue happens when run db=&gt; select * from &quot;ExxJobs&quot; where status=&quot;Ongoing&quot;; It returns 123456ERROR: column "Ongoing" does not existLINE 1: select * from "ExxJobs" where status="Ongoing"; ^ERROR: column "ongoing" does not existLINE 1: select * from "ExxJobs" where status=Ongoing; ^ Solution just change “” to ‘’. 12345db=&gt; select * from "ExxJobs" where status='Ongoing'; id | type| xxxJobId | xxxJobUrl | status | errorMessage | createdAt | updatedAt----+-----------------+----------+--------------------------------------------------------------------------------------------------------+---------+--------------+----------------------------+---------------------------- 16 | ... | 22947534 | &#123;"..."&#125; | Ongoing | | 2020-05-18 06:17:32.525+00 | 2020-05-18 06:17:32.544+00(1 row) similarly: 123456cecdb=&gt; delete from "ExxJobs" where 'xxxJobId'=22674314;ERROR: invalid input syntax for integer: "xxxJobId"LINE 1: delete from "ExxJobs" where 'xxxJobId'=22674314;db=&gt; delete from "ExxJobs" where "xxxJobId"='22674314';DELETE 1]]></content>
      <categories>
        <category>work</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>postgres</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker errors in daily use]]></title>
    <url>%2F2020%2F05%2F13%2Fdocker-error%2F</url>
    <content type="text"><![CDATA[Error1 Steps to reproduce the error:12$ kubectl get pods -AUnable to connect to the server: EOF According to this answer, I tried 12$ docker ps -a --filter name=k8s_kubedns_kube-dns --format "table &#123;&#123;.ID&#125;&#125;\t&#123;&#123;.Image&#125;&#125;"Error response from daemon: open \\.\pipe\docker_engine_linux: The system cannot find the file specified. 12345678$ docker psError response from daemon: open \\.\pipe\docker_engine_linux: The system cannot find the file specified.$ docker infoClient: Debug Mode: falseServer:ERROR: Error response from daemon: open \\.\pipe\docker_engine_linux: The system cannot find the file specifie d.errors pretty printing info Search for Error response from daemon, I found this issue same to mine Solution: Restart docker via docker desktop, right click and choose ‘restart’.]]></content>
      <categories>
        <category>work</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows errors in daily use]]></title>
    <url>%2F2020%2F05%2F13%2Fwindows-error%2F</url>
    <content type="text"><![CDATA[Error1 Steps to reproduce the error:12$ cp winpty.exe /usr/bincp: cannot create regular file '/usr/bin/winpty.exe': Permission denied 12$ sudo cp winpty.exe /usr/binbash: sudo: command not found 12$ whoamieshibij As above I have already been a root user (no need to run with sudo), so the only answer for this error is that the destination directory /usr/bin does not exists. Check: 12PS C:\Users\eshibij\Downloads\winpty-0.4.3-cygwin-2.8.0-x64\bin&gt; cd /usr/bincd : Cannot find path 'C:\usr\bin' because it does not exist. Solution: give up coping this file. Error2 Steps to reproduce the error: 12$ kubectl exec -it &lt;pod&gt; bashUnable to use a TTY - input is not a terminal or the right kind of file Solution: download winpyt.exe file from https://github.com/rprichard/winpty/releases and do the copy it to /usr/bin Note: do not use winpty-0.4.3-cygwin-2.8.0-ia32.tar.gz as the above link provided, cuz it will cause new issues missing ddl: C:/Program Files/Git/usr/bin/winpty.exe: error while loading shared libraries: cygwin1.dll: cannot open shared object file: No such file or directory. Using the other version winpty-0.4.3-msys2-2.7.0-x64.tar.gz After install winpty, you can use winpty kubectl exec -it &lt;pod&gt; -c &lt;container&gt; sh to access containers inside pods.]]></content>
      <categories>
        <category>work</category>
      </categories>
      <tags>
        <tag>cmd</tag>
        <tag>bash</tag>
        <tag>powershell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Failed starting postgres DB container via k8s on linux]]></title>
    <url>%2F2020%2F05%2F09%2Fpostgres-error-linux%2F</url>
    <content type="text"><![CDATA[When starting a postgres DB container via kubernetes on linux host server, it failed to start the container. 123[root@compute2 log]# kubectl get podNAME READY STATUS RESTARTS AGEtest-764dc8f84b-smg92 0/1 Error 3 49s 123456789101112131415161718[root@compute2 log]# kubectl logs test-764dc8f84b-smg92The files belonging to this database system will be owned by user &quot;postgres&quot;.This user must also own the server process.The database cluster will be initialized with locale &quot;en_US.utf8&quot;.The default database encoding has accordingly been set to &quot;UTF8&quot;.The default text search configuration will be set to &quot;english&quot;.Data page checksums are disabled.fixing permissions on existing directory /var/lib/postgresql/data ... okcreating subdirectories ... okselecting default max_connections ... 20selecting default shared_buffers ... 400kBselecting dynamic shared memory implementation ... posixcreating configuration files ... okchild process was terminated by signal 7initdb: removing contents of data directory &quot;/var/lib/postgresql/data&quot; Image is with no problem cuz I can do docker run to start container successfully. ————————————— Solution ————————————— https://github.com/docker-library/postgres/issues/451 there are several possible solutions to the problem: Modify the docker image to be able to set huge_pages = off in /usr/share/postgresql/postgresql.conf.sample before initdb was ran (this is what I did). Turn off huge page support on the system (vm.nr_hugepages = 0 in /etc/sysctl.conf). Fix Postgres’s fallback mechanism when huge_pages = try is set (the default). Modify the k8s manifest to enable huge page support (https://kubernetes.io/docs/tasks/manage-hugepages/scheduling-hugepages/). Modify k8s to show that huge pages are not supported on the system, when they are not enabled for a specific container. I tried the second way, and solve the issue successfully.]]></content>
      <categories>
        <category>work</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
        <tag>K8s</tag>
        <tag>linux</tag>
        <tag>postgres</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Errors encountered in using k8s]]></title>
    <url>%2F2020%2F04%2F08%2Fk8s-errors%2F</url>
    <content type="text"><![CDATA[This is a record in deploying k8s in work stage. Issue 1: failed to schedule pod for not running “VolumeBinding” filter plugindescribe pod: 1234Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling 55s (x19 over 26m) default-scheduler error while running &quot;VolumeBinding&quot; filter plugin for pod &quot;eri-cec-9dcd4d6c8-whvrm&quot;: pod has unbound immediate PersistentVolumeClaims check pod specs by kubectl edit pod &lt;pod-name&gt;: 12345678910111213141516171819202122volumes:- name: cec-database persistentVolumeClaim: claimName: eri-cec-database-pvc- name: cec-misc persistentVolumeClaim: claimName: eri-cec-misc-pvc- name: default-token-pxxg8 secret: defaultMode: 420 secretName: default-token-pxxg8status: conditions: - lastProbeTime: null lastTransitionTime: "2020-04-08T01:58:02Z" message: 'error while running "VolumeBinding" filter plugin for pod "eri-cec-9dcd4d6c8-whvrm": pod has unbound immediate PersistentVolumeClaims' reason: Unschedulable status: "False" type: PodScheduled phase: Pending qosClass: BestEffort The two persistentVolumeClaims were set during helm install: 1234567helm install -n eri ./cec-release-1.0.0.tgz \&gt; --set persistence.enabled=true \&gt; --set persistence.storageClass=nfs \&gt; --set persistence.database.size=5Gi \&gt; --set persistence.miscellaneous.size=5Gi \&gt; --set ingress.cecManager.hostName=dual-test \&gt; --set ingress.cecApi.hostName=dual-api 123456789101112131415161718192021222324252627282930NAME: eriLAST DEPLOYED: Wed Apr 8 09:58:00 2020NAMESPACE: defaultSTATUS: DEPLOYED======================================RESOURCES:==&gt; v1/DeploymentNAME AGEeri-cec 1s========================================&gt; v1/PersistentVolumeClaimNAME AGEeri-cec-database-pvc 2seri-cec-misc-pvc 2s========================================&gt; v1/Pod(related)NAME AGEeri-cec-9dcd4d6c8-whvrm 1s========================================&gt; v1/SecretNAME AGEeri-cec-database-secret 2s========================================&gt; v1/ServiceNAME AGEeri-cec 1s========================================&gt; v1beta1/IngressNAME AGEeri-cec-ingress 1s =========================solution========================= Refers: https://stackoverflow.com/questions/60774220/kubernetes-pod-has-unbound-immediate-persistentvolumeclaims https://blog.csdn.net/oguro/article/details/96964440 https://blog.csdn.net/liumiaocn/article/details/103388607 https://kubernetes.io/docs/tasks/configure-pod-container/configure-persistent-volume-storage/ From above info, there is something wrong with PVC (PersistentVolumeClaims), which leaves state “unbound”. The PVC should be bound to certain PV (PersistentVolume) which has enough capacity to hold the binding PVC. check PVCs and PVs:123456[root@host63 cec-installer]# kubectl get pvc -ANAMESPACE NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGEcec eri-sh-cec-database-pvc Pending nfs 125mcec eri-sh-cec-misc-pvc Pending nfs 125mdefault eri-cec-database-pvc Pending nfs 3h22mdefault eri-cec-misc-pvc Pending nfs 3h22m 12[root@host63 cec-installer]# kubectl get pv -ANo resources found There is no PV on current node-63, thus I create two PVs for db-pvc and misc-pvc.Make a directory for PVs first: 1[root@host63 mnt]# sudo mkdir /mnt/data check permission and capacity the PVC need: 1234567[root@host63 cec-installer]# kubectl edit pvc eri-sh-cec-database-pvc -n cec...accessModes: - ReadWriteOnceresources: requests: storage: 5Gi vi pv-init.yaml: 123456789101112131415161718192021222324252627apiVersion: v1kind: PersistentVolumemetadata: name: eri-sh-cec-database-pv labels: name: eri-sh-cec-database-pvspec: nfs: path: /mnt/data server: nfs accessModes: ["ReadWriteMany","ReadWriteOnce"] capacity: storage: 5Gi---apiVersion: v1kind: PersistentVolumemetadata: name: eri-sh-cec-misc-pv labels: name: eri-sh-cec-misc-pvspec: nfs: path: /mnt/data server: nfs accessModes: ["ReadWriteMany","ReadWriteOnce"] capacity: storage: 5Gi 1234567[root@host63 cec-installer]# kubectl apply -f pv-init.yamlpersistentvolume/eri-sh-cec-database-pv createdpersistentvolume/eri-sh-cec-misc-pv created[root@host63 cec-installer]# kubectl get pv -ANAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEeri-sh-cec-database-pv 5Gi RWO,RWX Retain Available 15seri-sh-cec-misc-pv 5Gi RWO,RWX Retain Available 15s PVC still not work, check its status: 123456789[root@host63 cec-installer]# kubectl describe pvc eri-sh-cec-database-pvc -n cecEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Warning ProvisioningFailed 54m (x3 over 104m) cluster.local/nfs-provisioner-nfs-server-provisioner_nfs-provisioner-nfs-server-provisioner-0_79370fad-78b7-11ea-8b82-66556e93189d failed to provision volume with StorageClass &quot;nfs&quot;: error getting NFS server IP for volume: service SERVICE_NAME=nfs-provisioner-nfs-server-provisioner is not valid; check that it has for ports map[&#123;111 UDP&#125;:true &#123;111 TCP&#125;:true &#123;2049 TCP&#125;:true &#123;20048 TCP&#125;:true] exactly one endpoint, this pod&apos;s IP POD_IP=192.168.220.144 Warning ProvisioningFailed 38m (x8 over 3h6m) cluster.local/nfs-provisioner-nfs-server-provisioner_nfs-provisioner-nfs-server-provisioner-0_79370fad-78b7-11ea-8b82-66556e93189d failed to provision volume with StorageClass &quot;nfs&quot;: error getting NFS server IP for volume: service SERVICE_NAME=nfs-provisioner-nfs-server-provisioner is not valid; check that it has for ports map[&#123;2049 TCP&#125;:true &#123;20048 TCP&#125;:true &#123;111 UDP&#125;:true &#123;111 TCP&#125;:true] exactly one endpoint, this pod&apos;s IP POD_IP=192.168.220.144 Normal Provisioning 21m (x16 over 3h6m) cluster.local/nfs-provisioner-nfs-server-provisioner_nfs-provisioner-nfs-server-provisioner-0_79370fad-78b7-11ea-8b82-66556e93189d External provisioner is provisioning volume for claim &quot;cec/eri-sh-cec-database-pvc&quot; Warning ProvisioningFailed 21m (x2 over 3h4m) cluster.local/nfs-provisioner-nfs-server-provisioner_nfs-provisioner-nfs-server-provisioner-0_79370fad-78b7-11ea-8b82-66556e93189d failed to provision volume with StorageClass &quot;nfs&quot;: error getting NFS server IP for volume: service SERVICE_NAME=nfs-provisioner-nfs-server-provisioner is not valid; check that it has for ports map[&#123;111 TCP&#125;:true &#123;2049 TCP&#125;:true &#123;20048 TCP&#125;:true &#123;111 UDP&#125;:true] exactly one endpoint, this pod&apos;s IP POD_IP=192.168.220.144 Normal ExternalProvisioning 87s (x742 over 3h6m) persistentvolume-controller waiting for a volume to be created, either by external provisioner &quot;cluster.local/nfs-provisioner-nfs-server-provisioner&quot; or manually created by system administrator Did not figure out Issue 2. The deployed pod (without nfs) would use ipv4 as default, and service nginx-ingress will use ipv4 address as default route, cannot change it.log nginx-ingress: 1234567891011121314151617181920212223242526272829303132333435363738394041[root@host63 cec-installer]# kubectl logs nginx-ingress-controller-64d58897bd-b99gw ------------------------------------------------------------------------------- NGINX Ingress controller Release: 0.29.0 Build: git-eedcdcdbf Repository: https://github.com/kubernetes/ingress-nginx nginx version: nginx/1.17.8 ------------------------------------------------------------------------------- I0407 10:17:14.810155 8 flags.go:215] Watching for Ingress class: nginx W0407 10:17:14.811042 8 flags.go:260] SSL certificate chain completion is disabled (--enable-ssl-chain-completion=false) W0407 10:17:14.811123 8 client_config.go:543] Neither --kubeconfig nor --master was specified. Using the inClusterConfig. This might not work. I0407 10:17:14.811367 8 main.go:193] Creating API client for https://192.167.0.1:443 I0407 10:17:14.820212 8 main.go:237] Running in Kubernetes cluster version v1.17 (v1.17.4) - git (clean) commit 8d8aa39598534325ad77120c120a22b3a990b5ea - platform linux/amd64 I0407 10:17:14.823302 8 main.go:91] Validated default/nginx-ingress-default-backend as the default backend. I0407 10:17:15.126113 8 main.go:102] SSL fake certificate created /etc/ingress-controller/ssl/default-fake-certificate.pem W0407 10:17:15.147723 8 store.go:657] Unexpected error reading configuration configmap: configmaps &quot;nginx-ingress-controller&quot; not found I0407 10:17:15.156374 8 nginx.go:263] Starting NGINX Ingress controller I0407 10:17:16.357204 8 nginx.go:307] Starting NGINX process I0407 10:17:16.357338 8 leaderelection.go:242] attempting to acquire leader lease default/ingress-controller-leader-nginx... W0407 10:17:16.358186 8 controller.go:394] Service &quot;default/nginx-ingress-default-backend&quot; does not have any active Endpoint I0407 10:17:16.358304 8 controller.go:137] Configuration changes detected, backend reload required. I0407 10:17:16.360127 8 status.go:86] new leader elected: nginx-ingress-controller-64d58897bd-cthrs I0407 10:17:16.450895 8 controller.go:153] Backend successfully reloaded. I0407 10:17:16.450966 8 controller.go:162] Initial sync, sleeping for 1 second. W0407 10:17:20.280746 8 controller.go:394] Service &quot;default/nginx-ingress-default-backend&quot; does not have any active Endpoint W0407 10:17:23.614240 8 controller.go:394] Service &quot;default/nginx-ingress-default-backend&quot; does not have any active Endpoint W0407 10:17:33.458971 8 controller.go:394] Service &quot;default/nginx-ingress-default-backend&quot; does not have any active Endpoint I0407 10:17:53.811527 8 leaderelection.go:252] successfully acquired lease default/ingress-controller-leader-nginx I0407 10:17:53.811566 8 status.go:86] new leader elected: nginx-ingress-controller-64d58897bd-b99gw W0407 10:18:00.868971 8 controller.go:394] Service &quot;default/nginx-ingress-default-backend&quot; does not have any active Endpoint I0408 03:14:30.743173 8 event.go:281] Event(v1.ObjectReference&#123;Kind:&quot;Ingress&quot;, Namespace:&quot;cec&quot;, Name:&quot;eri-sh-cec-ingress&quot;, UID:&quot;dd298fd3-3c16-42e8-a544-c7f942ec4e3e&quot;, APIVersion:&quot;networking.k8s.io/v1beta1&quot;, ResourceVersion:&quot;211359&quot;, FieldPath:&quot;&quot;&#125;): type: &apos;Normal&apos; reason: &apos;CREATE&apos; Ingress cec/eri-sh-cec-ingress W0408 03:14:34.068588 8 controller.go:921] Service &quot;default/eri-cec&quot; does not have any active Endpoint. W0408 03:14:34.068631 8 controller.go:921] Service &quot;default/eri-cec&quot; does not have any active Endpoint. W0408 03:14:34.068648 8 controller.go:921] Service &quot;cec/eri-sh-cec&quot; does not have any active Endpoint. W0408 03:14:34.068661 8 controller.go:921] Service &quot;cec/eri-sh-cec&quot; does not have any active Endpoint. I0408 03:14:53.817883 8 status.go:274] updating Ingress cec/eri-sh-cec-ingress status from [] to [&#123;10.136.40.63 &#125;] I0408 03:14:53.820045 8 event.go:281] Event(v1.ObjectReference&#123;Kind:&quot;Ingress&quot;, Namespace:&quot;cec&quot;, Name:&quot;eri-sh-cec-ingress&quot;, UID:&quot;dd298fd3-3c16-42e8-a544-c7f942ec4e3e&quot;, APIVersion:&quot;networking.k8s.io/v1beta1&quot;, ResourceVersion:&quot;211445&quot;, FieldPath:&quot;&quot;&#125;): type: &apos;Normal&apos; reason: &apos;UPDATE&apos; Ingress cec/eri-sh-cec-ingress W0408 03:14:53.820285 8 controller.go:921] Service &quot;default/eri-cec&quot; does not have any active Endpoint. W0408 03:14:53.820310 8 controller.go:921] Service &quot;default/eri-cec&quot; does not have any active Endpoint. W0408 03:14:53.820326 8 controller.go:921] Service &quot;cec/eri-sh-cec&quot; does not have any active Endpoint. W0408 03:14:53.820341 8 controller.go:921] Service &quot;cec/eri-sh-cec&quot; does not have any active Endpoint. Solved the problem of product service using default ipv4 as cluster-ip by adding new paras in helm deployment charts: ipFamily: below service: in values.yaml 1ipFamily: &#123;&#123;.Values.service.ipFamily&#125;&#125; below spec: in service.yaml --set service.ipFamily=IPv6 when helm install product Solution:Modify helm chart before installing ingress, in value.yaml, config: 12345hostNetwork: truereportNodeInternalIp: truedaemonset: useHostPort: truekind: DaemonSet you can also set service type and external_IP here.After helm install, check if you can visit service using hostname via host-ip. 12345678910[root@host63 cec-installer]# curl http://dual-ipv6:80&lt;!DOCTYPE html&gt;&lt;html&gt;...&lt;/html&gt;[root@host63 cec-installer]# curl http://dual-ipv4:80&lt;!DOCTYPE html&gt;&lt;html&gt;...&lt;/html&gt; also check with client UI. Issue 3. Failed to init tiller, pod creating error: rpc error: code = DeadlineExceeded desc = context deadline exceededpod hang on state ContainerCreating after doing helm init. describe pod: 12345678910111213141516[root@host59 ~]# kubectl describe -n kube-system pod tiller-deploy-969865475-sn2k2Name: tiller-deploy-969865475-sn2k2Namespace: kube-systemNode: host59/2001:1b74:88:9400::59:59Controlled By: ReplicaSet/tiller-deploy-969865475Containers: tiller: Container ID: Image: gcr.io/kubernetes-helm/tiller:v2.16.1 Image ID: Ports: 44134/TCP, 44135/TCPEvents: Type Reason Age From Message Normal Scheduled 54m default-scheduler Successfully assigned kube-system/tiller-deploy-969865475-sn2k2 to host59 Warning FailedCreatePodSandBox 2m47s (x13 over 50m) kubelet, host59 Failed to create pod sandbox: rpc error: code = DeadlineExceeded desc = context deadline exceeded Normal SandboxChanged 2m47s (x13 over 50m) kubelet, host59 Pod sandbox changed, it will be killed and re-created. check docker containers, which is already running, so there must be something wrong with docker 12[root@host59 ~]# systemctl status kubelet -lApr 17 17:25:27 host59 kubelet[19205]: E0417 17:25:27.660517 19205 dns.go:135] Nameserver limits were exceeded, some nameservers have been omitted, the applied nameserver line is: 10.221.16.11 10.221.16.10 150.236.34.180 1234[root@host59 ~]# journalctl -u kubelet -fApr 17 17:27:18 host59 kubelet[19205]: E0417 17:27:18.262418 19205 cni.go:385] Error deleting kube-system_tiller-deploy-969865475-sn2k2/f35df2a630d07b0ec7149fb06d7216c60a3c77a7118924c7b7eb9556b02f5cab from network multus/multus-cni-network: netplugin failed with no error messageApr 17 17:27:18 host59 kubelet[19205]: W0417 17:27:18.263092 19205 cni.go:331] CNI failed to retrieve network namespace path: Error: No such container: beb6e83c61bc47ba808dcc51e6c76e89817efb1f518fe28bc1083c99ad4721e1Apr 17 17:27:19 host59 kubelet[19205]: E0417 17:27:19.660435 19205 dns.go:135] Nameserver limits were exceeded, some nameservers have been omitted, the applied nameserver line is: 10.221.16.11 10.221.16.10 150.236.34.180 So the multus pod/container is not running correctly. Check the pod: 12345678[root@host59 ~]# kubectl describe pod -n kube-system pod kube-multus-ds-amd64-wz5xjName: kube-multus-ds-amd64-wz5xjNamespace: kube-systemNode: host59/2001:1b74:88:9400::59:59Events: Type Reason Age From Message Warning DNSConfigForming 117s (x291 over 6h7m) kubelet, host59 Nameserver limits were exceeded, some nameservers have been omitted, the applied nameserver line is: 10.221.16.11 10.221.16.10 150.236.34.180Error from server (NotFound): pods &quot;pod&quot; not found Delete pod kube-mutlus: 1kubectl delete -f multus-daemonset.yml still not work, edit deployment find: 12345678910111213141516171819[root@host59 opt]# kubectl edit deploy tiller-deploy -n kube-systemstatus: conditions: - lastTransitionTime: &quot;2020-04-20T01:53:55Z&quot; lastUpdateTime: &quot;2020-04-20T01:53:55Z&quot; message: Deployment does not have minimum availability. reason: MinimumReplicasUnavailable status: &quot;False&quot; type: Available - lastTransitionTime: &quot;2020-04-20T02:03:56Z&quot; lastUpdateTime: &quot;2020-04-20T02:03:56Z&quot; message: ReplicaSet &quot;tiller-deploy-b747845f&quot; has timed out progressing. reason: ProgressDeadlineExceeded status: &quot;False&quot; type: Progressing observedGeneration: 1 replicas: 1 unavailableReplicas: 1 updatedReplicas: 1 Finally find the reason: mutlus is not compatible with calico, thus Error deleting kube-system_tiller-deploy... from network multus/multus-cni-network: netplugin failed with no error message happened as above. Even if I delete mutlus before, it has already been configured in etcd config file under /etc/kubernetes. So modify related config and the tiller pod will turn to normal.]]></content>
      <categories>
        <category>work</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
        <tag>K8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Support ipv6/dualStack in K8s]]></title>
    <url>%2F2020%2F03%2F20%2Fk8s-ipv6-dualstack-support%2F</url>
    <content type="text"><![CDATA[记录惊天巨坑enable ipv6 and dual stack for our product，从k8s安装开始 0. 原来产品是本地安装测试的，仅支持ipv4安装很简便，但这次要求支持ipv6/dualStack，根据官网文档，我们需要1.16版本以上的kubernetes，kubectl version查看本地版本: 12Client Version: version.Info&#123;Major:"1", Minor:"14", GitVersion:"v1.14.8", GitCommit:"211047e9a1922595eaa3a1127ed365e9299a6c23", GitTreeState:"clean", BuildDate:"2019-10-15T12:11:03Z", GoVersion:"go1.12.10", Compiler:"gc", Platform:"windows/amd64"&#125;Server Version: version.Info&#123;Major:"1", Minor:"14", GitVersion:"v1.14.8", GitCommit:"211047e9a1922595eaa3a1127ed365e9299a6c23", GitTreeState:"clean", BuildDate:"2019-10-15T12:02:12Z", GoVersion:"go1.12.10", Compiler:"gc", Platform:"linux/amd64"&#125; 1.14。。赶紧查docker desktop自带的kubernetes怎么更新，发现要写deploy测试或者重装k8s? 感觉不适用。因为这是docker自带的不知道重装会不会有别的影响。决定直接装到我们组的remote server上，这样测试也可以一步到位。 登上remote server发现第二个坑，机子连不了外网。。。连yum install都必须自己配置本地yum repo…一开始是想自己再装一个能连外网的虚拟机，把docker和k8s下载下来打好包再transfer到remote server上。 setup redhat7 to local vm: error when setup vm: VT-x is not available (VERR_VMX_NO_VMX)solution: https://blog.csdn.net/imilano/article/details/83038682 (note: this action will affect the auto-start of docker) enable the subscription before downloading docker:https://blog.csdn.net/yl_1314/article/details/52044022 不太行，改用这个: https://github.com/wxdlong/ok8s 把包下到本地再放到60上 before downloading, need change user permission level on docker. run command with:1export MSYS_NO_PATHCONV=1 then add local user to group “docker-users”, “Hyper-V Administrators”,” Remote Desktop Users”,”Remote Management Users” 123PS H:\&gt; net localgroup docker-users ERICSSON\&lt;eid&gt; /addSystem error 1378 has occurred.The specified account name is already a member of the group. 12PS H:\&gt; net localgroup &quot;Hyper-V Administrators&quot; ERICSSON\&lt;eid&gt; /addThe command completed successfully. 123PS H:\&gt; net localgroup &quot;Remote Desktop Users&quot; ERICSSON\&lt;eid&gt; /addSystem error 1378 has occurred.The specified account name is already a member of the group. 12PS H:\&gt; net localgroup &quot;Remote Management Users&quot; ERICSSON\&lt;eid&gt; /addThe command completed successfully. check shared docker in DockerDesktopIf still can’t see the volume, relogon PC, sec, and reset credentials. download packages to local folder download 1$ docker run --rm -v '//c//Users//&lt;eid&gt;//download:/ok8s' registry.cn-hangzhou.aliyuncs.com/wxdlong/ok8s:v1.16.3 接下来就是把这个folder copy到host server上按教程往下走。 配置k8s和docker过程中遇到的错误 kubectl cluster-info return [error] The connection to the server localhost:8080 was refused - did you specify the right host or port? https://blog.csdn.net/wzygis/article/details/9135487012echo "export KUBECONFIG=/etc/kubernetes/admin.conf" &gt;&gt; ~/.bash_profilesource ~/.bash_profile 包里缺少flannel插件,自行安装 Copy /etc/kubernetes/admin.conf to $HOME/.kube/(on windows, on host server we just use /root)： 12345[root@192-168-1-61 ~]# mkdir -p /root/.kube[root@192-168-1-61 .kube]# cp -i /etc/kubernetes/admin.conf /root/.kube/config[root@192-168-1-61 .kube]# ls -ltr /root/.kube/total 8 -rw-------. 1 root root 5448 Mar 17 21:33 config 这一步可能是多余的，因为上面第一个错误已经export过路径了 check pod status 12345678910[root@192-168-1-61 ok8s]# kubectl get pods -ANAMESPACE NAME READY STATUS RESTARTS AGEkube-system coredns-5644d7b6d9-5sp86 0/1 Pending 0 15hkube-system coredns-5644d7b6d9-qjfz9 0/1 Pending 0 15hkube-system etcd-192-168-1-61.maas 1/1 Running 0 15hkube-system kube-apiserver-192-168-1-61.maas 1/1 Running 0 15hkube-system kube-controller-manager-192-168-1-61.maas 1/1 Running 0 15hkube-system kube-flannel-ds-amd64-vx4bw 1/1 Running 0 15hkube-system kube-proxy-h4gdc 1/1 Running 0 15hkube-system kube-scheduler-192-168-1-61.maas 1/1 Running 0 15h According to above result, the core DNS service is not started successfully. flannel still not work, check tail -f /var/log/messages found Unable to update cni config: no valid networks found in /etc/cni/net.d + [fork/exec /opt/ok8s/cni/flannel: permission denied fork/exec /opt/ok8s/cni/portmap: permission denied] go to folder cd /opt/ok8s/cni/ and run chmod +x *. tip: 无权限文件一般是白字，像上面这样授予全部权限会变为绿色，chmod 777 会把文件变为灰底 再次kubectl get pods -A可以看到两个core-dns node已经跑起来了 安装dashboard123[root@192-168-1-61 ok8s]# kubectl get pods -Akubernetes-dashboard dashboard-metrics-scraper-76585494d8-qb5mw 1/1 Running 0 101mkubernetes-dashboard kubernetes-dashboard-5996555fd8-88qz6 0/1 ImagePullBackOff 0 101m 这里pull image失败了，看了下应该是因为host server不能连外网，dashboard没大用处，这步暂时跳过 更换network插件为calico 装完flannel发现它还没支持ipv6，我人傻了，只好重新安装calico，先存一下calico支持ipv6 | dual-stack的官方文档, 以及非常详细的中文安装教程 kubeadm reset后更改pod-network-cidr，重新init cluster: 1[root@192-168-1-61 ok8s]# kubeadm init --v=7 --pod-network-cidr=192.168.0.0/16 --kubernetes-version=v1.16.3 Calico作为CNI插件安装。必须通过传递–network-plugin=cni参数将kubelet配置为使用CNI网络, 这里–pod-network-cidr=192.168.0.0就是是用来给 controller-manager 用作自动分配pod子网 (用作给每个node上的pod分配IP address) follow this official doc 由于不能连外网导致image pull不下来，手动下载过去 1kube-system calico-node-vcbmc 0/1 Init:ImagePullBackOff 0 9m12s 12345678910[root@192-168-1-61 nodeagent~uds]# kubectl describe pods calico-node-vcbmc -n kube-systemEvents:Type Reason Age From MessageNormal Scheduled 9m44s default-scheduler Successfully assigned kube-system/calico-node-vcbmc to 192-168-1-61.maasWarning Failed 9m3s kubelet, 192-168-1-61.maas Failed to pull image &quot;calico/cni:v3.13.1&quot;: rpc error: code = Unknown desc = Error response from daemon: Get https://registry-1.docker.io/v2/: dial tcp: lookup registry-1.docker.io on 10.136.40.87:53: server misbehavingNormal Pulling 7m37s (x4 over 9m44s) kubelet, 192-168-1-61.maas Pulling image &quot;calico/cni:v3.13.1&quot;Warning Failed 7m22s (x3 over 9m29s) kubelet, 192-168-1-61.maas Failed to pull image &quot;calico/cni:v3.13.1&quot;: rpc error: code = Unknown desc = Error response from daemon: Get https://registry-1.docker.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)Warning Failed 7m22s (x4 over 9m29s) kubelet, 192-168-1-61.maas Error: ErrImagePullWarning Failed 7m9s (x6 over 9m28s) kubelet, 192-168-1-61.maas Error: ImagePullBackOffNormal BackOff 4m36s (x16 over 9m28s) kubelet, 192-168-1-61.maas Back-off pulling image &quot;calico/cni:v3.13.1&quot; download calico:v3.13.1 via https://docs.projectcalico.org/release-notes/, transfer the tgz package to host server. [root@192-168-1-61 calico]# docker load --input /home/eshibij/calico-v3.13.1/release-v3.13.1/images/calico-node.tar –&gt; load calico image, check: 123[root@192-168-1-61 calico]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEcalico/node v3.13.1 2e5029b93d4a 5 days ago 260MB 把pod2daemon-flexvol, calico-cni, calico-kube-controllers也一起load了 [error] pod describe find calico 0/1 nodes are available: 1 node(s) had taints that the pod didn&#39;t tolerate. –&gt; 这个一般是有另一个它依赖的node还没起来，查看/var/log/messages –&gt; [failed to find plugin &quot;calico&quot; in path [/opt/ok8s/cni] –&gt; 原因是ok8s把加载的image里的默认文件挂载路径改成了/opt/ok8s/cni。可以直接在/opt/cni/bin (插件加载默认路径) 下找到calico和calico-ipam二进制文件copy到/opt/ok8s/cni下，也可以修改calico.yaml里的文件路径后重新apply -f1234567891011[root@192-168-1-61 cni]# kubectl get pods -ANAMESPACE NAME READY STATUS RESTARTS AGEkube-system calico-kube-controllers-788d6b9876-dzlrz 1/1 Running 0 15hkube-system calico-node-fttdx 1/1 Running 0 15hkube-system coredns-5644d7b6d9-dl8ft 1/1 Running 0 15hkube-system coredns-5644d7b6d9-dzrdv 1/1 Running 0 15hkube-system etcd-192-168-1-61.maas 1/1 Running 0 15hkube-system kube-apiserver-192-168-1-61.maas 1/1 Running 0 15hkube-system kube-controller-manager-192-168-1-61.maas 1/1 Running 0 15hkube-system kube-proxy-l54q7 1/1 Running 0 15hkube-system kube-scheduler-192-168-1-61.maas 1/1 Running 0 15h modify kubelet.service add --feature-gates=&quot;IPv6DualStack=true&quot; after ExecStart=/opt/ok8s/bin/kubelet in file /usr/lib/systemd/system/kubelet.service host server network config refer https://www.jianshu.com/p/e92dec9f9cf4 add configs to /etc/sysctl.d/98-ok8s.conf 1234net.ipv6.conf.all.disable_ipv6 = 0net.ipv6.conf.default.disable_ipv6 = 0net.ipv6.conf.lo.disable_ipv6 = 0net.ipv6.conf.all.forwarding=1 run sysctl -p to make these configs work enable ipv6 on host server, add setting to /etc/sysconfig/network 1NETWORKING_IPV6=yes check ifcfg-xxx under /etc/sysconfig/networkscripts/: 12IPV6INIT=yesIPV6_AUTOCONF=yes generate kubeconfig file to parse configs refer https://github.com/Jason-ZW/kubernetes-dual-stack-poc/blob/86f51df6766a3091fea2838416eb55dc6b83d44e/kubeadm/kubeconfig.config [error] k8s v1.16.3 cannot parse subnet with comma https://github.com/kubernetes/kubeadm/issues/1828 update K8s to v1.17.4packages/images updated: binary file: kubeadm, kubelet, kubectl, kube-proxy, kube-scheduler docker image: controller-manager, proxy, scheduler, apiserver, etcd, coredns Note: the coredns official package has to be loaded as docker import coredns_1.6.5_linux_amd64.tgz (reason see https://visionary-s.github.io/%2F2020%2F01%2F20%2Fdocker%2F)check package version after replace kubeadm file: kubeadm config images list reinstall following official docs [error] failed to execute operation file exists when systemctl enable kubelet solution : systemctl disable kubelet first, then redo enable action. ref [error] cannot use “fe80::2a80:23ff:feb5:a150” as the bind address for the API Server 查到kubeconfig.conf中: 1234567apiVersion: kubeadm.k8s.io/v1beta1kind: InitConfigurationnodeRegistration: kubeletExtraArgs: ##cgroup-driver: &quot;systemd&quot;localAPIEndpoint: advertiseAddress: fe80::2a80:23ff:feb5:a150 原因：不能用scope为link的ipv6地址，要用scope为global的2001:250:4000:2000::53 etcd 3.4.3 官方镜像有点问题，导致etcd启动连接老是失败solution: 把老版3.1的换了个tag。。。 kube-controller-manager-192-168-1-61.maas CrashLoopBackOff describe node, 发现在无限重启 12 Warning Unhealthy 91s kubelet, 192-168-1-61.maas Liveness probe failed: Get https://127.0.0.1:10257/healthz: dial tcp 127.0.0.1:10257: connect: connection refusedWarning BackOff 57s (x12 over 4m30s) kubelet, 192-168-1-61.maas Back-off restarting failed container check docker logs； 1234E0325 03:00:25.517141 1 core.go:91] Failed to start service controller: WARNING: no cloud provider provided, services of type LoadBalancer will failE0325 03:00:25.638913 1 core.go:232] failed to start cloud node lifecycle controller: no cloud provider providedE0325 03:00:37.441597 1 controllermanager.go:521] Error starting &quot;nodeipam&quot;F0325 03:00:37.441623 1 controllermanager.go:235] error starting controllers: New CIDR set failed; the node CIDR size is too big solution: ? install calico error when starting calico node 1kube-system calico-node-mzcnp 0/1 Init:CrashLoopBackOff 2 31s descirbe event: 12345 Normal Scheduled 56s default-scheduler Successfully assigned kube-system/calico-node-mzcnp to 192-168-1-61.maasNormal Pulled 12s (x4 over 56s) kubelet, 192-168-1-61.maas Container image &quot;calico/cni:v3.13.1&quot; already present on machineNormal Created 12s (x4 over 56s) kubelet, 192-168-1-61.maas Created container upgrade-ipamWarning Failed 12s (x4 over 56s) kubelet, 192-168-1-61.maas Error: failed to start container &quot;upgrade-ipam&quot;: Error response from daemon: OCI runtime create failed: container_linux.go:346: starting container process caused &quot;exec: \&quot;/opt/ok8s/cni/calico-ipam\&quot;: stat /opt/ok8s/cni/calico-ipam: no such file or directory&quot;: unknownWarning BackOff 8s (x4 over 41s) kubelet, 192-168-1-61.maas Back-off restarting failed container but I found the calico-ipam is already under /opt/ok8s/cni/原因：calico.yaml配置里路径写错了，按官网的来 calico node起不起来 1234567891011 [root@192-168-1-61 calico]# kubectl get pods -ANAMESPACE NAME READY STATUS RESTARTS AGEkube-system calico-kube-controllers-788d6b9876-wkd5h 0/1 ContainerCreating 0 39mkube-system calico-node-64q4h 0/1 Running 0 59skube-system coredns-6955765f44-k9cb5 0/1 ContainerCreating 0 45mkube-system coredns-6955765f44-nznr9 0/1 ContainerCreating 0 45mkube-system etcd-192-168-1-61.maas 1/1 Running 0 45mkube-system kube-apiserver-192-168-1-61.maas 1/1 Running 0 45mkube-system kube-controller-manager-192-168-1-61.maas 1/1 Running 0 45mkube-system kube-proxy-ggjvb 1/1 Running 0 45mkube-system kube-scheduler-192-168-1-61.maas 1/1 Running 0 45m describe calico-kube-controller: 1234 Warning FailedScheduling 59s (x30 over 39m) default-scheduler 0/1 nodes are available: 1 node(s) had taints that the pod didn&apos;t tolerate.Normal Scheduled 57s default-scheduler Successfully assigned kube-system/calico-kube-controllers-788d6b9876-wkd5h to 192-168-1-61.maasWarning FailedCreatePodSandBox 54s kubelet, 192-168-1-61.maas Failed to create pod sandbox: rpc error: code = Unknown desc = [failed to set up sandbox container &quot;27761f7a236bf9c092826ecb546dddad7c44a40fa1891faf6c45b14f330ad25d&quot; network for pod &quot;calico-kube-controllers-788d6b9876-wkd5h&quot;: networkPlugin cni failed to set up pod &quot;calico-kube-controllers-788d6b9876-wkd5h_kube-system&quot; network: error getting ClusterInformation: Get https://[10.24.0.1]:443/apis/crd.projectcalico.org/v1/clusterinformations/default: dial tcp 10.24.0.1:443: connect: connection refused, failed to clean up sandbox container &quot;27761f7a236bf9c092826ecb546dddad7c44a40fa1891faf6c45b14f330ad25d&quot; network for pod &quot;calico-kube-controllers-788d6b9876-wkd5h&quot;: networkPlugin cni failed to teardown pod &quot;calico-kube-controllers-788d6b9876-wkd5h_kube-system&quot; network: error getting ClusterInformation: Get https://[10.24.0.1]:443/apis/crd.projectcalico.org/v1/clusterinformations/default: dial tcp 10.24.0.1:443: connect: connection refused]Normal SandboxChanged 9s (x5 over 53s) kubelet, 192-168-1-61.maas Pod sandbox changed, it will be killed and re-created. 原因： https://[10.24.0.1]:443这个应该对应kubeconfig中kube-proxy下的clusterCIDR，应该跟kubelet下的podSubnet保持一致?（我用了serviceSubnet的网段）还是不行，后面又改成了纯ipv6环境，配置文件kubeconfig.yml如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243apiVersion: kubeadm.k8s.io/v1beta2kind: InitConfigurationlocalAPIEndpoint: advertiseAddress: 2001:250:4000:2000::53 bindPort: 6443nodeRegistration: criSocket: /var/run/dockershim.sock taints: - effect: NoSchedule key: node-role.kubernetes.io/master kubeletExtraArgs: node-ip: "2001:250:4000:2000::53"#---apiServer: timeoutForControlPlane: 4m0sapiVersion: kubeadm.k8s.io/v1beta2certificatesDir: /etc/kubernetes/pkiclusterName: kubernetescontrolPlaneEndpoint: "[2001:250:4000:2000::53]:6443"dns: type: CoreDNSimageRepository: k8s.gcr.iocontrollerManager: extraArgs: #feature-gates: IPv6DualStack=true bind-address: "::" service-cluster-ip-range: fd03::/120 cluster-cidr: "fd04::/120"kind: ClusterConfigurationkubernetesVersion: v1.17.4networking: dnsDomain: cluster.local serviceSubnet: "fd03::/120" podSubnet: "fd04::/120"#---apiVersion: kubelet.config.k8s.io/v1beta1kind: KubeletConfigurationfailSwapOn: false#---apiVersion: kubeproxy.config.k8s.io/v1alpha1kind: KubeProxyConfigurationclusterCIDR: "fd03::/120"mode: "ipvs" 修改了calico.yaml执行脚本的参数如下：！这是dual的，ipv6-only的把ipv4的部分去掉 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556kind: ConfigMap...data: ... cni_network_config: |- &#123; "name": "k8s-pod-network", "cniVersion": "0.3.1", "plugins": [ &#123; ... "ipam": &#123; "type": "calico-ipam", "assign_ipv4": "true", "assign_ipv6": "true", "ipv4_pools": ["192.170.30.0/16", "default-ipv4-ippool"], "ipv6_pools": ["fd03::/120", "default-ipv6-ippool"] &#125;, ... &#125;, ... ] &#125; ... ...#---kind: DaemonSet...spec: ... template: ... spec: ... containers: - name: calico-node image: calico/node:v3.13.1 env: ... - name: CALICO_IPV4POOL_CIDR value: "192.170.30.0/16" ... # Disable IPv6 on Kubernetes. - name: FELIX_IPV6SUPPORT value: "true" ... - name: CALICO_IPV6POOL_CIDR value: fd04::/120 - name: IP6 value: "autodetect" # !注意，这是后来做outgress发现的，ipv6环境默认不会配网关，see # https://docs.projectcalico.org/reference/node/configuration # 所以这里要加个参数 - name: CALICO_IPV6POOL_NAT_OUTGOING value: true ... create检查service地址能不能对上，具体debug步骤忘了，大概用了这些命令： 12ss -atnlp | grep 443netstat -an|grep 6443 又装了个Nginx pod以后，试图写一个测试service看能不能通过Nginx ping通ipv6地址，失败 service.yaml 12345678910111213apiVersion: v1kind: Servicemetadata: name: cecspec: ipFamily: IPv6 ports: - name: http port: 8080 protocol: TCP targetPort: 80 selector: app: nginx nginx.yaml 12345678910111213141516171819piVersion: apps/v1 # for versions before 1.9.0 use apps/v1beta2kind: Deploymentmetadata: name: nginx-deploymentspec: selector: matchLabels: app: nginx replicas: 2 # tells deployment to run 2 pods matching the template template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.14.2 ports: - containerPort: 80 debug 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061root@192-168-1-61 ok8s]# kubectl apply -f service.yamlservice/cec created[root@192-168-1-61 ok8s]# kubectl get service -ANAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEdefault cec ClusterIP fd03::7d &lt;none&gt; 8080/TCP 35sdefault kubernetes ClusterIP fd03::1 &lt;none&gt; 443/TCP 4h36mkube-system kube-dns ClusterIP fd03::a &lt;none&gt; 53/UDP,53/TCP,9153/TCP 4h36m[root@192-168-1-61 ok8s]# kubectl describe -n default pod nginx-deployment-574b87c764-qptmz...Node: 192-168-1-61.maas/2001:250:4000:2000::53Labels: app=nginxAnnotations: cni.projectcalico.org/podIP: fd04::d5/128 cni.projectcalico.org/podIPs: fd04::d5/128IP: fd04::d5Containers: nginx: Container ID: docker://199c74a7f44d431d95091d991025e43b24dca7fa9cc9d77e3781af1b89f160ce Image: nginx:1.14.2 Port: 80/TCP Host Port: 0/TCP...[root@192-168-1-61 ok8s]# kubectl get pods -o yaml | grep -i podip cni.projectcalico.org/podIP: fd04::d5/128 cni.projectcalico.org/podIPs: fd04::d5/128 podIP: fd04::d5 podIPs:[root@192-168-1-61 ok8s]# kubectl describe svc cec...Selector: app=nginxType: ClusterIPIP: fd03::7dPort: http 8080/TCPTargetPort: 80/TCPEndpoints: [fd04::d5]:80[root@192-168-1-61 ok8s]# curl -vvv -k http://[fd03::7d]:8080 -g* About to connect() to fd03::7d port 8080 (#0)* Trying fd03::7d...* Connection refused* Failed connect to fd03::7d:8080; Connection refused* Closing connection 0curl: (7) Failed connect to fd03::7d:8080; Connection refused[root@192-168-1-61 ok8s]# &gt;/dev/tcp/fd03::7d/8080-bash: connect: Connection refused-bash: /dev/tcp/fd03::7d/8080: Connection refused[root@192-168-1-61 ok8s]# ipvsadm -lnIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConnTCP [fd03::1]:443 rr -&gt; [2001:250:4000:2000::53]:6443 Masq 1 4 0 TCP [fd03::a]:53 rr -&gt; [fd04::cf]:53 Masq 1 0 0 -&gt; [fd04::d7]:53 Masq 1 0 0 TCP [fd03::a]:9153 rr -&gt; [fd04::cf]:9153 Masq 1 0 0 -&gt; [fd04::d7]:9153 Masq 1 0 0 TCP [fd03::7d]:8080 rr -&gt; [fd04::d5]:80 Masq 1 0 0 UDP [fd03::a]:53 rr -&gt; [fd04::cf]:53 Masq 1 0 0 -&gt; [fd04::d7]:53 Masq 1 0 0 123456[root@192-168-1-61 cec-installer]# kubectl get svc,deployNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEservice/kubernetes ClusterIP fd03::1 &lt;none&gt; 443/TCP 137mNAME READY UP-TO-DATE AVAILABLE AGEdeployment.apps/nginx-deployment 2/2 2 2 105m 12345678910111213141516171819202122232425262728293031323334353637383940[root@192-168-1-61 ok8s]# kubectl exec -it nginx-deployment-574b87c764-qptmz bashroot@nginx-deployment-574b87c764-qptmz:/# &gt;/dev/tcp/127.0.0.1/80root@nginx-deployment-574b87c764-qptmz:/# &gt;/dev/tcp/fd04::d5/80bash: connect: Connection refusedbash: /dev/tcp/fd04::d5/80: Connection refusedroot@nginx-deployment-574b87c764-qptmz:/# cd /etc/nginx/root@nginx-deployment-574b87c764-qptmz:/etc/nginx# cat nginx.confuser nginx;worker_processes 1;error_log /var/log/nginx/error.log warn;pid /var/run/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include /etc/nginx/mime.types; default_type application/octet-stream; log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf;&#125;// not modified on my desktop, thus skip the modification hereroot@nginx-deployment-574b87c764-qptmz:/etc/nginx# nginx -s reload2020/03/26 09:01:37 [notice] 28#28: signal process startedroot@nginx-deployment-574b87c764-qptmz:/etc/nginx# &gt;/dev/tcp/fd04::d5/80 install helm/tiller/nfs/ingress Background: no connection to outer internet on host server, install helm and tiller locally, export tiller image and transfer it to host server. Step1: install helm 1234567891011121314151617181920212223wget https://get.helm.sh/helm-v2.16.1-linux-amd64.tar.gz// transfer package to host server:/var/tmp/xxx-installer/[root@192-168-1-61 cec-installer]# tar zxvf helm-v2.16.1-linux-amd64.tar.gzlinux-amd64/linux-amd64/helmlinux-amd64/LICENSElinux-amd64/tillerlinux-amd64/README.md[root@192-168-1-61 cec-installer]# sudo install **/helm /usr/bin[root@192-168-1-61 cec-installer]# helm versionClient: &amp;version.Version&#123;SemVer:&quot;v2.16.1&quot;, GitCommit:&quot;bbdfe5e7803a12bbdf97e94cd847859890cf4050&quot;, GitTreeState:&quot;clean&quot;&#125;Error: could not find tiller[root@192-168-1-61 cec-installer]# helm initCreating /root/.helmCreating /root/.helm/repositoryCreating /root/.helm/repository/cacheCreating /root/.helm/repository/localCreating /root/.helm/pluginsCreating /root/.helm/startersCreating /root/.helm/cache/archiveCreating /root/.helm/repository/repositories.yamlAdding stable repo with URL: https://kubernetes-charts.storage.googleapis.comError: error initializing: Looks like &quot;https://kubernetes-charts.storage.googleapis.com&quot; is not a valid chart repository or cannot be reached:etes-charts.storage.googleapis.com/index.yaml: dial tcp: lookup kubernetes-charts.storage.googleapis.com on 10.136.40.87:53: server misbehavi here refered https://www.jianshu.com/p/2bb1dfdadee8 12345// 这一步不知道要不要做，反正我先做了[root@192-168-1-61 cec-installer]# cd linux-amd64/[root@192-168-1-61 linux-amd64]# lsLICENSE README.md helm tiller[root@192-168-1-61 linux-amd64]# vim rbac-config.yaml 123456789101112131415161718apiVersion: v1kind: ServiceAccountmetadata: name: tiller namespace: kube-system---apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRoleBindingmetadata: name: tillerroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects: - kind: ServiceAccount name: tiller namespace: kube-system 123[root@192-168-1-61 linux-amd64]# kubectl create -f rbac-config.yamlserviceaccount/tiller createdclusterrolebinding.rbac.authorization.k8s.io/tiller created Step2: init tiller save local tiller image and transfer it to host server, then follow the answer@Amit-Thawait 这里还遇到一个问题，本地win10的helm和tiller以前装的是2.14，这次用了2.16，不知如何升级，问了一下，原来是用2.16的helm.exe和tiller.exe文件替换掉/.helm/下的俩对应exe再init一遍就行了，估计linux上的更新就是替换一下二进制文件吧。。 1234567891011121314[root@host63 cec-installer]# docker image tag 1f92aa902d73 gcr.io/kubernetes-helm/tiller:v2.16.1[root@192-168-1-61 cec-installer]# helm init --client-only --skip-refreshCreating /root/.helm/repository/repositories.yamlAdding stable repo with URL: https://kubernetes-charts.storage.googleapis.comAdding local repo with URL: http://127.0.0.1:8879/charts$HELM_HOME has been configured at /root/.helm.Not installing Tiller due to &apos;client-only&apos; flag having been set// load tiller image[root@192-168-1-61 cec-installer]# helm init$HELM_HOME has been configured at /root/.helm.Tiller (the Helm server-side component) has been installed into your Kubernetes Cluster.Please note: by default, Tiller is deployed with an insecure &apos;allow unauthenticated users&apos; policy.To prevent this, run `helm init` with the --tiller-tls-verify flag.For more information on securing your installation see: https://docs.helm.sh/using_helm/#securing-your-helm-installation helm error happens: 1234[root@192-168-1-61 cec-installer]# helm versionClient: &amp;version.Version&#123;SemVer:&quot;v2.16.1&quot;, GitCommit:&quot;bbdfe5e7803a12bbdf97e94cd847859890cf4050&quot;, GitTreeState:&quot;clean&quot;&#125;E0326 23:21:17.649683 11541 portforward.go:400] an error occurred forwarding 39127 -&gt; 44134: error forwarding port 44134 to pod 8d197e975824256d2de574f4577161702560b55a4aa70978bac91f2e43abe712, uid : unable to do port forwarding: socat not foundE0326 23:21:18.652732 11541 portforward.go:400] an error occurred forwarding 39127 -&gt; 44134: error forwarding port 44134 to pod 8d197e975824256d2de574f4577161702560b55a4aa70978bac91f2e43abe712, uid : unable to do port forwarding: socat not found According to https://www.kubernetes.org.cn/3879.html, this error happens due to rr is not set to permitted in k8s net config, install socat to fix it. (internal yum repository has build up, thus download directly) 1234[root@192-168-1-61 cec-installer]# yum install socat.x86_64[root@192-168-1-61 cec-installer]# helm versionClient: &amp;version.Version&#123;SemVer:&quot;v2.16.1&quot;, GitCommit:&quot;bbdfe5e7803a12bbdf97e94cd847859890cf4050&quot;, GitTreeState:&quot;clean&quot;&#125;Server: &amp;version.Version&#123;SemVer:&quot;v2.16.4&quot;, GitCommit:&quot;5e135cc465d4231d9bfe2c5a43fd2978ef527e83&quot;, GitTreeState:&quot;clean&quot;&#125; 版本好像没对上，懒得重装了凑合用吧。 Step3: install nfs [error] cannot install nfs: 12helm install stable/nfs-server-provisioner --name nfs-provisioner --set persistence.storageClass=nfs --set persistence.size=20Gi --set rbac.create=trueError: validation failed: [storageclasses.storage.k8s.io &quot;nfs&quot; not found, serviceaccounts &quot;nfs-provisioner-nfs-server-provisioner&quot; not found, clusterroles.rbac.authorization.k8s.io &quot;nfs-provisioner-nfs-server-provisioner&quot; not found, clusterrolebindings.rbac.authorization.k8s.io &quot;nfs-provisioner-nfs-server-provisioner&quot; not found, services &quot;nfs-provisioner-nfs-server-provisioner&quot; not found, statefulsets.apps &quot;nfs-provisioner-nfs-server-provisioner&quot; not found] try to downgrade tiller to 2.16.1 on windows: 12$ helm reset --force$ helm init -i registry.cn-hangzhou.aliyuncs.com/google_containers/tiller:v2.16.1 nfs installed on windows successfully: 1234$ kubectl get storageclassNAME PROVISIONER AGEhostpath (default) docker.io/hostpath 7d3hnfs cluster.local/nfs-provisioner-nfs-server-provisioner 102s for offline linux server, firstly download helm chart package, then package the chart files to tgz, helm install it on host server: 12345[root@192-168-1-61 cec-installer]# helm install -n nfs-provisioner ./nfs-servier-provisoner.tgz \&gt; --set persistence.storageClass=nfs \&gt; --set persistence.size=20GiError: release nfs-provisioner failed: namespaces &quot;default&quot; is forbidden: User &quot;system:serviceaccount:kube-system:default&quot; cannot get resource &quot;namespaces&quot; in API group &quot;&quot; in the namespace &quot;default&quot; 应该是helm创建sa时未添加helm-tiller，按这个步骤加上就ok了: 12345678910111213141516171819[root@192-168-1-61 cec-installer]# kubectl create serviceaccount --namespace kube-system helm-tillerserviceaccount/helm-tiller created[root@192-168-1-61 cec-installer]# kubectl create clusterrolebinding helm-tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=kube-system:helm-tillerclusterrolebinding.rbac.authorization.k8s.io/helm-tiller-cluster-rule created[root@192-168-1-61 cec-installer]# helm init --service-account=helm-tiller --upgrade$HELM_HOME has been configured at /root/.helm.Tiller (the Helm server-side component) has been updated to gcr.io/kubernetes-helm/tiller:v2.16.1 .[root@192-168-1-61 cec-installer]# helm install -n nfs-provisioner ./nfs-servier-provisoner.tgz --set persistence.storageClass=nfs --set persistence.size=20GiNAME: nfs-provisionerLAST DEPLOYED: Mon Mar 30 02:13:19 2020NAMESPACE: defaultSTATUS: DEPLOYED...[root@192-168-1-61 cec-installer]# kubectl get storageclassNAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGEnfs cluster.local/nfs-provisioner-nfs-server-provisioner Delete Immediate true 2m42s Step4: install nginx-ingress, similar to installing nfs 123docker load -i ingress-nginx.tar.gzdocker image tag 20c7790fd73d quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.29.0helm install -n nginx-ingress ./nginx-ingress-deploy.tgz --set rbac.create=true finally, start to install our product 产品jenkins-ci因为没人维护挂了。。只好本地打包 step1: ./startindesignenv.sh -c -d -d步骤中最后为npm start所以最后不会停要手动cancel进程。build + deploy完了以后可以在coreservice/backend/webroot（类似target）下找到拷贝过去的前端编译文件。 step2: 在任一service目录下（例：coreservice）$ docker build -t &lt;package-name&gt; .执行打包，coreservice比较特殊，因为前后端一体所以要执行第一步先把前端整合到后端，其他service直接打包即可。 error1:12Step 1/15 : FROM node:10.15.3-alpineerror pulling image configuration: Get https://registry-1.docker.io/v2/library/node/blobs.. net/http: TLS handshake timeout solution : network not stable, ignore and build again error2:123456789 Step 2/15 : RUN apk add --no-cache bash openssl fetch http://dl-cdn.alpinelinux.org/alpine/v3.9/main/x86_64/APKINDEX.tar.gz WARNING: Ignoring http://dl-cdn.alpinelinux.org/alpine/v3.9/main/x86_64/APKINDEX.tar.gz: network error (check Internet connection and firewall) ERROR: unsatisfiable constraints: bash (missing): required by: world[bash] openssl (missing): required by: world[openssl]The command '/bin/sh -c apk add --no-cache bash openssl' returned a non-zero code: 2 solution: didnt figure out the detailed reason, but restart docker cannot solve this issue. Thanks to Ye who taught me to add 12ENV HTTP_PROXY="http://www-proxy.lmera.ericsson.se:8080"ENV HTTPS_PROXY="http://www-proxy.lmera.ericsson.se:8080" to Dockerfile, the problem due to no connection to external link while running the alpinelinux. the proxy ENV config will also take effect on container running on host server after loading, we would better use --build-arg when execute docker build, see https://www.cntofu.com/book/139/image/dockerfile/arg.mde.g. $ docker build -t core-cec . –build-arg HTTP_PROXY=”http://www-proxy.lmera.ericsson.se:8080&quot; Step3: install on linux server docker load -i &lt;package&gt; helm install -n eri2 ./cec-release-1.0.0.tgz --set service.type=NodePort --set persistence.enabled=false --set persistence.storageClass=nfs --set persistence.database.size=5Gi --set persistence.miscellaneous.size=5Gi deployed but got error, when building one service container, run image as container and enter to check:12345678910111213141516171819202122232425 [root@192-168-1-61 cec-installer]# docker run -it registry/cec-sai:1.0.0 sh /opt/ericsson/cec/saiservice # /usr/local/bin/npm start /opt/ericsson/cec/saiservice/node_modules/bindings/bindings.js:91 throw e ^ Error: Error loading shared library /opt/ericsson/cec/saiservice/node_modules/libxmljs/build/Release/xmljs.node: Exec format errorat Object.Module._extensions..node (internal/modules/cjs/loader.js:730:18)at Module.load (internal/modules/cjs/loader.js:600:32)at tryModuleLoad (internal/modules/cjs/loader.js:539:12)at Function.Module._load (internal/modules/cjs/loader.js:531:3)at Module.require (internal/modules/cjs/loader.js:637:17)at require (internal/modules/cjs/helpers.js:22:18)at bindings (/opt/ericsson/cec/saiservice/node_modules/bindings/bindings.js:84:48)at Object.&lt;anonymous&gt; (/opt/ericsson/cec/saiservice/node_modules/libxmljs/lib/bindings.js:1:99)at Module._compile (internal/modules/cjs/loader.js:701:30)at Object.Module._extensions..js (internal/modules/cjs/loader.js:712:10)npm ERR! code ELIFECYCLEnpm ERR! errno 1npm ERR! CEC_SAI_Handler@1.0.0 start: `node server.js`npm ERR! Exit status 1npm ERR!npm ERR! Failed at the CEC_SAI_Handler@1.0.0 start script.npm ERR! This is probably not a problem with npm. There is likely additional logging output above.npm ERR! A complete log of this run can be found in:npm ERR! /root/.npm/_logs/2020-03-31T02_30_46_424Z-debug.log it may due to the some nodes in npm_modules not work both on windows and linux env. ref: https://dzone.com/articles/packaging-a-node-app-for-docker-from-windows solution: remove node_modules before docker image build, npm install all packages in docker container, thus it will be generated in linux format. 12345...COPY . ./RUN rm -rf node_modules...npm install build and check image: 12345678910$ docker build -t cec-sai . --build-arg HTTP_PROXY="http://www-proxy.lmera.ericsson.se:8080"$ winpty docker run -it cec-sai sh/opt/ericsson/cec/saiservice # find / -name npm/usr/local/lib/node_modules/npm/usr/local/lib/node_modules/npm/bin/npm/usr/local/bin/npm/opt/ericsson/cec/saiservice # /usr/local/bin/npm start&gt; CEC_SAI_Handler@1.0.0 start /opt/ericsson/cec/saiservice&gt; node server.jssequelize deprecated String based operators are now deprecated. Please use Symbol based operators for better security, read more at http://docs.sequelizejs.com/manual/tutorial/querying.html#operators node_modules/sequelize/lib/sequelize.js:245:13 save image: 1$ docker save -o cec-sai-200327.tar.gz cec-sai then load it to host server on linux Run enm server via docker container is a simpler way, use docker run -itd --name &lt;simulator-name&gt; -p 8091:8091 -v &lt;volume-path&gt; &lt;image-id or name&gt;, volune path can be skipped to set, remind to expose port 8091 or the container cannot be accessed. (port depends on your design) Step4: install simulator save image on windows, load it to linux, then start simulator service on linux server: 12$ kubectl create deployment xxx-simulator --image=xxx-simulator:1.0.0deployment.apps/xxx-simulator created get simulator ip address: 123$ kubectl get pod -l app=enm-simulator -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESxxx-simulator-79d68f588f-8l2fq 1/1 Running 0 4m3s fd04::fb 192-168-1-61.maas &lt;none&gt; &lt;none&gt; Test functionalities [error1] connot apply ipv6 address in our settings. solution: change validation regex from ^http(s)?://[\\w\\.\\-?=%&amp;:/]+$ to ^http(s)?://([\[\\w\\.\\-?=%&amp;:/](\])?)+$ [error2] cannot connect to simulator when do cell import:solution: modify default HOST config in server.js from ‘0.0.0.0’ to ‘’. see official node.js docs section = server.listen(options[, callback]) here I record my debug history: 123456[root@192-168-1-61 ~]# kubectl exec -it xxx-simulator-79d68f588f-8l2fq bashbash-4.4# netstat -tunlpActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:8091 0.0.0.0:* LISTEN 23/nodetcp 0 0 0.0.0.0:8092 0.0.0.0:* LISTEN 23/node the ip is deafult in ipv4 format, so enter our core service (frontend and backend) pod to check more. 123456[root@192-168-1-61 ~]# kubectl exec -it -c xxx-core eri1-xxx-6c4b88cd75-7plb8 bashbash-4.4# ping6 fd04::fdPING fd04::fd (fd04::fd): 56 data bytes64 bytes from fd04::fd: seq=0 ttl=63 time=0.144 ms64 bytes from fd04::fd: seq=1 ttl=63 time=0.179 ms64 bytes from fd04::fd: seq=2 ttl=63 time=0.069 ms fd04::fd is the ipv6 address of simulator, so simulator can be accessed by core service. 1234567891011bash-4.4# netstat -tunlpActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:5432 0.0.0.0:* LISTEN -tcp 0 0 :::8082 :::* LISTEN -tcp 0 0 :::8083 :::* LISTEN -tcp 0 0 :::8084 :::* LISTEN -tcp 0 0 :::8888 :::* LISTEN 16/nodetcp 0 0 :::5432 :::* LISTEN -tcp 0 0 :::8443 :::* LISTEN 16/nodetcp 0 0 :::8585 :::* LISTEN 16/node ports are all correct, so there might be errors in simulator codes 1234567[root@192-168-1-61 ~]# kubectl exec -it enm-simulator-77c8886b88-7ksxk bashbash-4.4# grep -i host /opt/eri../xxx/simulatorservice/server.jsconst HOST = &apos;0.0.0.0&apos;;httpServer.listen(HTTP_PORT, HOST, () =&gt; &#123; LOGGER.info(&quot;HTTP Server is running on : http://%s:%s&quot;, HOST, HTTP_PORT);httpsServer.listen(HTTPS_PORT, HOST, () =&gt; &#123; ... 果然。。。config default HOST = ‘0.0.0.0’ –&gt; HOST = ‘’ system error : connect ECONNREFUSED 127.0.0.1:8091,ENM=http://[fd04::fe]:8091 this error indicate the default route the simulator service connect to is not correct, check in codes I found: 12345678910111213module.exports = &#123; ENMSERVICEPROTOCO: process.env.enmserviceprotoco || 'http:', ENMSERVICEPORT: process.env.enmserviceport || 8083, ENMSERVICEHOST: process.env.enmservicehost || '', ENMNODEPROTOCO: process.env.enmnodeprotocol || 'http:', ENMNODEPORT: process.env.enmnodeport || 8091, ENMNODEHOST: process.env.enmnodehost || 'localhost', CORENODEPROTOCO: process.env.corenodeprotocol || 'http:', CORENODEPORT: process.env.corenodeport || 8585, CORENODEHOST: process.env.corenodehost || 'localhost',&#125; I guess there should be a ENV parameter configured in xxx simulator deployment.yaml. To temporarily fix this problem, I edit the deployment config of xxx-simulator, refer answer and k8s official doc: 123456789101112131415...spec: ... template: metadata: creationTimestamp: null labels: app: xxx-simulator spec: containers: - env: - name: enmnodehost value: '[fd04::fe]' image: xxx-simulator:1.0.0... 这方法不对，原因：connect ECONNREFUSED 127.0.0.1:8091是enmservice和simulator在通信，这个相当于连了localhost:8091 (查看enmservice的log也确实如此)，理论上应连[fd04::fe]:8091。问题出在enmservice request export of simulator的地址，所以改simulator的container启动配置没用。检查simulator的export代码，发现当时写的时候没考虑到ipv6，因为我们的create完job以后从simulator export的jobUrl是这么传的。。 12const fqdn = req.headers &amp;&amp; req.headers["host"] ? req.headers["host"].split(':')[0] : null;JOBSDATA = new JOBS(moJobId, fqdn); 所以error message里会出现http://[fd04:8091/bulk-con...这种url 12345678910"message": "Error: connect ECONNREFUSED ::1:8091","options": &#123; "ca": [ "" ], "jar": &#123;&#125;, "url": "http://[fd04:8091/bulk-configuration/v1/import-jobs/jobs/18974277/files", "method": "POST" ...&#125; 改了一下 12345678910111213var fqdn = ""; if (req.headers &amp;&amp; req.headers["host"]) &#123; const headerHost = req.headers["host"]; if (/\[/.test(headerHost)) &#123; let start = headerHost.indexOf('['); let end = headerHost.indexOf(']'); fqdn = headerHost.slice(start, end + 1); &#125; else &#123; fqdn = headerHost.split(':')[0]; &#125; &#125; else &#123; fqdn = null; &#125;]]></content>
      <categories>
        <category>work</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker CMD for daily use]]></title>
    <url>%2F2020%2F01%2F20%2Fdocker%2F</url>
    <content type="text"><![CDATA[images Display images on current server: 1$ docker images rename image: 12345REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEoldName latest d583c3ac45fd 26 minutes ago 685.5 MB######## change to ########REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEnewName latest d583c3ac45fd 26 minutes ago 685.5 MB 123$ docker image tag oldName:latest newName:latestor$ docker image tag d583c3ac45fd newName:latest Notice: this operation is equal to “copy” + “rename”, thus there will be two repositories “oldName” and “newName” after change. If you want to remove “oldName”, use docker rmi oldName. docker load / import docker load can load images which is released via docker save1$ docker load -i &lt;package&gt;(tar/tar.gz) docker import imports some packages that is released via docker export1$ docker import &lt;package&gt; &lt;repository-name:tag-version&gt; note: there might be &lt;none&gt; repository name and &lt;none&gt; TAG after import, this is because we did not commit its name when importing. we can rename it after it is imported. check build logs get container id 1$ docker ps -a # list all docker images, get container id here get logs for certain container 1$ docker logs &lt;container-id&gt; set time limit (get latest 30 mins logs) 1$ docker logs --since 30m &lt;container-id&gt; docker save existed imagefor some cases you might want to save local images and reload on another host server. Here I use tiller as an example. get image id123$ docker images |grep tilleror$ docker images|findstr tiller 12registry.cn-hangzhou.aliyuncs.com/google_containers/tiller v2.16.4 7eece2e1da99 2 days ago 89.1MBgcr.io/kubernetes-helm/tiller v2.14.3 2d0a693df3ba 7 months ago 94.2MB save target image to local tar.gz1$ docker save 7eece2e1da99 &gt; tiller.tar.gz now you can find the tiller.tar.gz under current folder, use docker load -i &lt;pack&gt; for reload on other server. image is being used by running container xxxxxxxxfollow the error messages, do docker stop &lt;container-id&gt;, then delete the container by docker rm &lt;container-id&gt;, finally do docker rmi &lt;image-id&gt; delete images/containers in batchesdelete images named 1$ docker images | grep '&lt;none&gt;' | awk '&#123;print $3&#125;' | xargs docker rmi delete all stopped containers 1$ docker ps -a | grep 'Exited' | awk '&#123;print $1&#125;' | xargs docker stop | xargs docker rm]]></content>
      <categories>
        <category>work</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>cmd</tag>
      </tags>
  </entry>
</search>
